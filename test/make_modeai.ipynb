{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "57e415a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd494858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ä¼ç¥¨æ—¥ä»˜",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "æ­£å‘³é‡é‡",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "å“å",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "4b283be8-3ae7-41a0-9d95-f0f8e3482a08",
       "rows": [
        [
         "0",
         "2020-01-06 00:00:00",
         "470.0",
         "æ··åˆå»ƒæ£„ç‰©B"
        ],
        [
         "1",
         "2020-01-06 00:00:00",
         "390.0",
         "ãã®ä»–"
        ],
        [
         "2",
         "2020-01-06 00:00:00",
         "120.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "3",
         "2020-01-06 00:00:00",
         "1720.0",
         "æ··åˆå»ƒæ£„ç‰©B"
        ],
        [
         "4",
         "2020-01-06 00:00:00",
         "320.0",
         "é¸åˆ¥"
        ],
        [
         "5",
         "2020-01-06 00:00:00",
         "740.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "6",
         "2020-01-06 00:00:00",
         "810.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "7",
         "2020-01-06 00:00:00",
         "20.0",
         "è»½é‡ç‰©ç³»ã€€ï¼¡"
        ],
        [
         "8",
         "2020-01-06 00:00:00",
         "260.0",
         "æ··åˆå»ƒæ£„ç‰©B"
        ],
        [
         "9",
         "2020-01-06 00:00:00",
         "20.0",
         "æœ¨ããšA"
        ],
        [
         "10",
         "2020-01-06 00:00:00",
         "490.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "11",
         "2020-01-06 00:00:00",
         "290.0",
         "ãã®ä»–"
        ],
        [
         "12",
         "2020-01-06 00:00:00",
         "290.0",
         "ãã®ä»–"
        ],
        [
         "13",
         "2020-01-06 00:00:00",
         "330.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "14",
         "2020-01-06 00:00:00",
         "180.0",
         "æ··åˆå»ƒæ£„ç‰©ï¼ˆç„¼å´ç‰©ï¼‰"
        ],
        [
         "15",
         "2020-01-06 00:00:00",
         "250.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "16",
         "2020-01-06 00:00:00",
         "230.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "17",
         "2020-01-06 00:00:00",
         "1690.0",
         "ãã®ä»–"
        ],
        [
         "18",
         "2020-01-06 00:00:00",
         "230.0",
         "ãã®ä»–"
        ],
        [
         "19",
         "2020-01-06 00:00:00",
         "1150.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "20",
         "2020-01-06 00:00:00",
         "60.0",
         "æœ¨ããšA"
        ],
        [
         "21",
         "2020-01-06 00:00:00",
         "330.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "22",
         "2020-01-06 00:00:00",
         "2090.0",
         "æ··åˆå»ƒæ£„ç‰©B"
        ],
        [
         "23",
         "2020-01-06 00:00:00",
         "700.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "24",
         "2020-01-06 00:00:00",
         "360.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "25",
         "2020-01-06 00:00:00",
         "1300.0",
         "æ··åˆå»ƒæ£„ç‰©B"
        ],
        [
         "26",
         "2020-01-06 00:00:00",
         "770.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "27",
         "2020-01-06 00:00:00",
         "290.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "28",
         "2020-01-06 00:00:00",
         "140.0",
         "æœ¨ããšA"
        ],
        [
         "29",
         "2020-01-06 00:00:00",
         "940.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "30",
         "2020-01-06 00:00:00",
         "150.0",
         "ï¼§ï¼£ã€€è»½é‰„ãƒ»ã‚¹ãƒï¼ãƒ«é¡"
        ],
        [
         "31",
         "2020-01-06 00:00:00",
         "160.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "32",
         "2020-01-06 00:00:00",
         "460.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "33",
         "2020-01-06 00:00:00",
         "80.0",
         "æ··åˆå»ƒæ£„ç‰©(ï½¿ï¾Œï½§ï½°)"
        ],
        [
         "34",
         "2020-01-06 00:00:00",
         "110.0",
         "æ··åˆå»ƒæ£„ç‰©ï¼ˆå®‰å®šå‹ï¼‰"
        ],
        [
         "35",
         "2020-01-06 00:00:00",
         "20.0",
         "é¸åˆ¥"
        ],
        [
         "36",
         "2020-01-06 00:00:00",
         "30.0",
         "ãã®ä»–"
        ],
        [
         "37",
         "2020-01-06 00:00:00",
         "30.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "38",
         "2020-01-06 00:00:00",
         "150.0",
         "è»½é‡ç‰©ç³»ã€€ï¼¡"
        ],
        [
         "39",
         "2020-01-06 00:00:00",
         "130.0",
         "æ··åˆå»ƒæ£„ç‰©ï¼ˆå®‰å®šå‹ï¼‰"
        ],
        [
         "40",
         "2020-01-06 00:00:00",
         "160.0",
         "é¸åˆ¥"
        ],
        [
         "41",
         "2020-01-06 00:00:00",
         "420.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "42",
         "2020-01-06 00:00:00",
         "1290.0",
         "æ··åˆå»ƒæ£„ç‰©"
        ],
        [
         "43",
         "2020-01-06 00:00:00",
         "800.0",
         "æ··åˆå»ƒæ£„ç‰©B"
        ],
        [
         "44",
         "2020-01-06 00:00:00",
         "390.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "45",
         "2020-01-06 00:00:00",
         "1070.0",
         "æ··åˆå»ƒæ£„ç‰©B"
        ],
        [
         "46",
         "2020-01-06 00:00:00",
         "2830.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "47",
         "2020-01-06 00:00:00",
         "1580.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ],
        [
         "48",
         "2020-01-06 00:00:00",
         "230.0",
         "æ··åˆå»ƒæ£„ç‰©B"
        ],
        [
         "49",
         "2020-01-06 00:00:00",
         "430.0",
         "æ··åˆå»ƒæ£„ç‰©A"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 210749
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ä¼ç¥¨æ—¥ä»˜</th>\n",
       "      <th>æ­£å‘³é‡é‡</th>\n",
       "      <th>å“å</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>470.0</td>\n",
       "      <td>æ··åˆå»ƒæ£„ç‰©B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>390.0</td>\n",
       "      <td>ãã®ä»–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>120.0</td>\n",
       "      <td>æ··åˆå»ƒæ£„ç‰©A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>æ··åˆå»ƒæ£„ç‰©B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>320.0</td>\n",
       "      <td>é¸åˆ¥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210744</th>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>350.0</td>\n",
       "      <td>æ··åˆå»ƒæ£„ç‰©A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210745</th>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>ï¾€ï½²ï¾”(ï¾ï½²ï¾™ç„¡)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210746</th>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>450.0</td>\n",
       "      <td>æ··åˆå»ƒæ£„ç‰©A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210747</th>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>430.0</td>\n",
       "      <td>æ··åˆå»ƒæ£„ç‰©A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210748</th>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>250.0</td>\n",
       "      <td>è»½é‡ç‰©ç³»B(ï½¸ï¾ï¾—ï½½ï½³ï½°ï¾™)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210749 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ä¼ç¥¨æ—¥ä»˜    æ­£å‘³é‡é‡              å“å\n",
       "0      2020-01-06   470.0          æ··åˆå»ƒæ£„ç‰©B\n",
       "1      2020-01-06   390.0             ãã®ä»–\n",
       "2      2020-01-06   120.0          æ··åˆå»ƒæ£„ç‰©A\n",
       "3      2020-01-06  1720.0          æ··åˆå»ƒæ£„ç‰©B\n",
       "4      2020-01-06   320.0              é¸åˆ¥\n",
       "...           ...     ...             ...\n",
       "210744 2025-05-26   350.0          æ··åˆå»ƒæ£„ç‰©A\n",
       "210745 2025-05-26    20.0       ï¾€ï½²ï¾”(ï¾ï½²ï¾™ç„¡)\n",
       "210746 2025-05-26   450.0          æ··åˆå»ƒæ£„ç‰©A\n",
       "210747 2025-05-26   430.0          æ··åˆå»ƒæ£„ç‰©A\n",
       "210748 2025-05-26   250.0  è»½é‡ç‰©ç³»B(ï½¸ï¾ï¾—ï½½ï½³ï½°ï¾™)\n",
       "\n",
       "[210749 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/work/app/data/input/filtered_result.csv\")\n",
    "df[\"ä¼ç¥¨æ—¥ä»˜\"] = pd.to_datetime(df[\"ä¼ç¥¨æ—¥ä»˜\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7e0d8e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import jpholiday\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "# === è£œåŠ©é–¢æ•° ===\n",
    "\n",
    "# --- ç¥æ—¥ãƒ•ãƒ©ã‚°åˆ¤å®šé–¢æ•° ---\n",
    "def make_holiday_flag(date):\n",
    "    return int(jpholiday.is_holiday(date) or date.weekday() >= 5)\n",
    "\n",
    "# --- å“ç›®åˆ†é¡é–¢æ•° ---\n",
    "def classify_item(item: str) -> str:\n",
    "    if \"æ··åˆå»ƒæ£„ç‰©A\" in item:\n",
    "        return \"æ··åˆA\"\n",
    "    elif \"æ··åˆå»ƒæ£„ç‰©B\" in item:\n",
    "        return \"æ··åˆB\"\n",
    "    else:\n",
    "        return \"ãã®ä»–\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a960ce60",
   "metadata": {},
   "source": [
    "## ç‰¹å¾´é‡ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "feccd27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_previous_year_feature(df_pivot: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_prev_year = df_pivot.copy()\n",
    "    df_prev_year.index = df_prev_year.index + pd.DateOffset(years=1)\n",
    "    df_prev_year_sum = df_prev_year.sum(axis=1).to_frame(name=\"å‰å¹´åŒæœŸé‡é‡\")\n",
    "    df_prev_year_sum = df_prev_year_sum.sort_index()\n",
    "\n",
    "    # å…ƒ df_pivot ã« merge ã—ã¦ \"å‰å¹´åŒæœŸé‡é‡\" ã‚’åˆ—ã¨ã—ã¦è¿½åŠ ã—ãŸ DataFrame ã‚’è¿”ã™\n",
    "    df_current = df_pivot.copy()\n",
    "    df_current = df_current.sort_index()\n",
    "    df_current = df_current.merge(\n",
    "        df_prev_year_sum,\n",
    "        how=\"left\",\n",
    "        left_index=True,\n",
    "        right_index=True\n",
    "    )\n",
    "\n",
    "    df_current[\"å‰å¹´åŒæœŸé‡é‡\"] = df_current[\"å‰å¹´åŒæœŸé‡é‡\"].fillna(0)\n",
    "\n",
    "    return df_current[[\"å‰å¹´åŒæœŸé‡é‡\"]]\n",
    "\n",
    "\n",
    "def compute_previous_year_ratio(df_pivot: pd.DataFrame) -> pd.DataFrame:\n",
    "    # å‰å¹´åŒæœŸé‡é‡\n",
    "    df_prev_year_sum = add_previous_year_feature(df_pivot)\n",
    "\n",
    "    # å…¨ä½“å¹³å‡æ¬å…¥é‡ï¼ˆå‰å¹´ã®ã¿ï¼‰\n",
    "    prev_year_dates = df_pivot.index - pd.DateOffset(years=1)\n",
    "    mask_prev_year = df_pivot.index.isin(prev_year_dates)\n",
    "    total_prev_year_weight = df_pivot.loc[mask_prev_year].sum(axis=1).mean()\n",
    "\n",
    "    # æ¯”ç‡ = å‰å¹´åŒæœŸé‡é‡ / å‰å¹´å¹³å‡\n",
    "    df_prev_year_sum[\"å‰å¹´åŒæœŸæ¯”ç‡\"] = df_prev_year_sum[\"å‰å¹´åŒæœŸé‡é‡\"] / total_prev_year_weight\n",
    "    df_prev_year_sum[\"å‰å¹´åŒæœŸæ¯”ç‡\"] = df_prev_year_sum[\"å‰å¹´åŒæœŸæ¯”ç‡\"].fillna(0)\n",
    "\n",
    "    return df_prev_year_sum[[\"å‰å¹´åŒæœŸæ¯”ç‡\"]]\n",
    "\n",
    "\n",
    "def add_holiday_adjacent_flag(dates: pd.Index) -> pd.Series:\n",
    "    # ç¥æ—¥ãƒ•ãƒ©ã‚°ï¼ˆã‚ãªãŸã® make_holiday_flag ã‚’ä½¿ã†ï¼‰\n",
    "    holiday_flags = dates.map(make_holiday_flag).astype(int)\n",
    "\n",
    "    # é€£ä¼‘å‰å¾Œãƒ•ãƒ©ã‚°åˆæœŸåŒ–\n",
    "    adjacent_flags = np.zeros(len(dates), dtype=int)\n",
    "\n",
    "    # ãƒ«ãƒ¼ãƒ—ã§å‰å¾Œåˆ¤å®š\n",
    "    for i in range(1, len(dates) - 1):\n",
    "        # é€£ä¼‘ä¸­ãªã‚‰1\n",
    "        if holiday_flags[i] == 1:\n",
    "            adjacent_flags[i] = 1\n",
    "        # é€£ä¼‘å‰æ—¥\n",
    "        elif holiday_flags[i - 1] == 1:\n",
    "            adjacent_flags[i] = 1\n",
    "        # é€£ä¼‘ç¿Œæ—¥\n",
    "        elif holiday_flags[i + 1] == 1:\n",
    "            adjacent_flags[i] = 1\n",
    "\n",
    "    return pd.Series(adjacent_flags, index=dates, name=\"é€£ä¼‘å‰å¾Œãƒ•ãƒ©ã‚°\")\n",
    "\n",
    "def add_month_start_end_flags(dates: pd.Index) -> pd.DataFrame:\n",
    "    df = pd.DataFrame(index=dates)\n",
    "    df[\"day\"] = dates.day\n",
    "    df[\"days_in_month\"] = dates.days_in_month\n",
    "\n",
    "    df[\"æœˆåˆãƒ•ãƒ©ã‚°\"] = (df[\"day\"] <= 3).astype(int)\n",
    "    df[\"æœˆæœ«ãƒ•ãƒ©ã‚°\"] = (df[\"days_in_month\"] - df[\"day\"] <= 2).astype(int)\n",
    "\n",
    "    return df[[\"æœˆåˆãƒ•ãƒ©ã‚°\", \"æœˆæœ«ãƒ•ãƒ©ã‚°\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c5d14ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.Series]:\n",
    "    df = df.copy()\n",
    "    df[\"ä¼ç¥¨æ—¥ä»˜\"] = pd.to_datetime(df[\"ä¼ç¥¨æ—¥ä»˜\"])\n",
    "    df[\"å“ç›®åˆ†é¡\"] = df[\"å“å\"].apply(classify_item)\n",
    "\n",
    "    df_daily = df.groupby([\"ä¼ç¥¨æ—¥ä»˜\", \"å“ç›®åˆ†é¡\"])[\"æ­£å‘³é‡é‡\"].sum().reset_index()\n",
    "    df_pivot = df_daily.pivot(index=\"ä¼ç¥¨æ—¥ä»˜\", columns=\"å“ç›®åˆ†é¡\", values=\"æ­£å‘³é‡é‡\").fillna(0)\n",
    "    df_pivot = df_pivot.sort_index()\n",
    "\n",
    "    df_feat = df_pivot.copy()\n",
    "    df_feat[\"æ›œæ—¥\"] = df_feat.index.dayofweek\n",
    "    df_feat[\"æœˆ\"] = df_feat.index.month\n",
    "    df_feat[\"ç¥æ—¥ãƒ•ãƒ©ã‚°\"] = df_feat.index.map(make_holiday_flag)\n",
    "    df_feat[\"å‰æ—¥åˆè¨ˆ\"] = df_pivot.sum(axis=1).shift(1)\n",
    "\n",
    "    for col in df_pivot.columns:\n",
    "        df_feat[f\"å‰æ—¥_{col}\"] = df_pivot[col].shift(1)\n",
    "\n",
    "    # --- å‰å¹´åŒæœŸé‡é‡ merge ---\n",
    "    df_feat = df_feat.merge(\n",
    "        add_previous_year_feature(df_pivot),\n",
    "        how=\"left\",\n",
    "        left_index=True,\n",
    "        right_index=True\n",
    "    )\n",
    "    df_feat[\"å‰å¹´åŒæœŸé‡é‡\"] = df_feat[\"å‰å¹´åŒæœŸé‡é‡\"].fillna(0)\n",
    "\n",
    "    # æœˆåˆï¼æœˆæœ«ãƒ•ãƒ©ã‚°\n",
    "    df_feat = df_feat.merge(\n",
    "        add_month_start_end_flags(df_feat.index),\n",
    "        how=\"left\",\n",
    "        left_index=True,\n",
    "        right_index=True\n",
    "    )\n",
    "\n",
    "    # --- é€£ä¼‘å‰å¾Œãƒ•ãƒ©ã‚°ï¼ˆreset_indexå‰ã«ä»˜ã‘ã‚‹ï¼ï¼‰---\n",
    "    df_feat[\"é€£ä¼‘å‰å¾Œãƒ•ãƒ©ã‚°\"] = add_holiday_adjacent_flag(df_feat.index)\n",
    "\n",
    "    # --- ç›®çš„å¤‰æ•°ï¼ˆç¿Œæ—¥åˆè¨ˆé‡é‡ï¼‰---\n",
    "    df_feat[\"ç¿Œæ—¥åˆè¨ˆ\"] = df_pivot.sum(axis=1).shift(-1)\n",
    "\n",
    "    # --- æœ€å¾Œã« dropna + reset_index ---\n",
    "    df_feat = df_feat.dropna().reset_index()\n",
    "\n",
    "    X = df_feat.drop(columns=[\"ä¼ç¥¨æ—¥ä»˜\", \"ç¿Œæ—¥åˆè¨ˆ\"])\n",
    "    y = df_feat[\"ç¿Œæ—¥åˆè¨ˆ\"]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a256bf74",
   "metadata": {},
   "source": [
    "## ãƒ¢ãƒ‡ãƒ«å‡¦ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3937b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Foldå˜ä½ã®å­¦ç¿’ãƒ»è©•ä¾¡ ---\n",
    "def train_and_evaluate_fold(fold, X_train, X_test, y_train, y_test):\n",
    "    # --- LightGBMãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ---\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "    \n",
    "    # --- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ---\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"mae\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 31,\n",
    "        \"max_depth\": 7,\n",
    "        \"min_data_in_leaf\": 20,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 5,\n",
    "    }\n",
    "    \n",
    "    # --- å­¦ç¿’ ---\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_eval],\n",
    "        num_boost_round=2000,\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=100),\n",
    "            log_evaluation(period=100),\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    # --- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å´ã®è©•ä¾¡ ---\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    \n",
    "    # --- ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å´ã®è©•ä¾¡ ---\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2_test = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # --- çµæœè¡¨ç¤º ---\n",
    "    print(f\"\\nğŸ“‚ Fold {fold+1}\")\n",
    "    print(f\"ğŸ“Š MAE:       {mae:.2f} kg\")\n",
    "    print(f\"ğŸ“Š Train RÂ²:  {r2_train:.4f}\")\n",
    "    print(f\"ğŸ“Š Test  RÂ²:  {r2_test:.4f}\")\n",
    "    \n",
    "    return mae, r2_train, r2_test\n",
    "\n",
    "# --- Foldå¹³å‡çµæœå‡ºåŠ› ---\n",
    "def print_fold_summary(mae_list, r2_train_list, r2_test_list):\n",
    "    print(\"\\nâœ… å…¨Foldå¹³å‡MAE: {:.2f} kg\".format(np.mean(mae_list)))\n",
    "    print(\"âœ… å…¨Foldå¹³å‡Train RÂ²: {:.4f}\".format(np.mean(r2_train_list)))\n",
    "    print(\"âœ… å…¨Foldå¹³å‡Test  RÂ²: {:.4f}\".format(np.mean(r2_test_list)))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ea33bc",
   "metadata": {},
   "source": [
    "## ãƒ¡ã‚¤ãƒ³å‡¦ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2551da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 8653.35\tvalid_1's l1: 13314.2\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's l1: 10689.8\tvalid_1's l1: 12647.7\n",
      "\n",
      "ğŸ“‚ Fold 1\n",
      "ğŸ“Š MAE:       12647.65 kg\n",
      "ğŸ“Š Train RÂ²:  0.6807\n",
      "ğŸ“Š Test  RÂ²:  0.5018\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 8255.34\tvalid_1's l1: 15280.9\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's l1: 9989.23\tvalid_1's l1: 14981.4\n",
      "\n",
      "ğŸ“‚ Fold 2\n",
      "ğŸ“Š MAE:       14981.43 kg\n",
      "ğŸ“Š Train RÂ²:  0.6985\n",
      "ğŸ“Š Test  RÂ²:  0.5151\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 8700.21\tvalid_1's l1: 13070\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's l1: 10201.8\tvalid_1's l1: 12705.3\n",
      "\n",
      "ğŸ“‚ Fold 3\n",
      "ğŸ“Š MAE:       12705.32 kg\n",
      "ğŸ“Š Train RÂ²:  0.7097\n",
      "ğŸ“Š Test  RÂ²:  0.5767\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 8670.91\tvalid_1's l1: 11660.4\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's l1: 9906.24\tvalid_1's l1: 11419.3\n",
      "\n",
      "ğŸ“‚ Fold 4\n",
      "ğŸ“Š MAE:       11419.26 kg\n",
      "ğŸ“Š Train RÂ²:  0.7272\n",
      "ğŸ“Š Test  RÂ²:  0.5781\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 8778.02\tvalid_1's l1: 13522.9\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's l1: 9708.71\tvalid_1's l1: 13247.1\n",
      "\n",
      "ğŸ“‚ Fold 5\n",
      "ğŸ“Š MAE:       13247.07 kg\n",
      "ğŸ“Š Train RÂ²:  0.7306\n",
      "ğŸ“Š Test  RÂ²:  0.5298\n",
      "\n",
      "âœ… å…¨Foldå¹³å‡MAE: 13000.15 kg\n",
      "âœ… å…¨Foldå¹³å‡Train RÂ²: 0.7093\n",
      "âœ… å…¨Foldå¹³å‡Test  RÂ²: 0.5403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === ãƒ¡ã‚¤ãƒ³å‡¦ç† ===\n",
    "\n",
    "# --- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆã“ã“ã¯ã‚ãªãŸã®å…ƒã® df ã‚’ç”¨æ„ã—ã¦ãŠãï¼‰ ---\n",
    "# ä¾‹: df = pd.read_csv(\"your_data.csv\")\n",
    "# ä»Šå›ã¯æ—¢ã« df ãŒå®šç¾©æ¸ˆã¿ã¨ã—ã¦é€²ã‚ã¾ã™\n",
    "\n",
    "X, y = prepare_features(df)\n",
    "\n",
    "# --- TimeSeriesSplitè¨­å®š ---\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# --- foldã”ã¨ã®è©•ä¾¡ç”¨ ---\n",
    "fold_mae_list = []\n",
    "fold_r2_train_list = []\n",
    "fold_r2_test_list = []\n",
    "\n",
    "# --- ãƒ¢ãƒ‡ãƒ«ãƒ«ãƒ¼ãƒ— ---\n",
    "for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    mae, r2_train, r2_test = train_and_evaluate_fold(fold, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    fold_mae_list.append(mae)\n",
    "    fold_r2_train_list.append(r2_train)\n",
    "    fold_r2_test_list.append(r2_test)\n",
    "\n",
    "# --- çµæœã¾ã¨ã‚è¡¨ç¤º ---\n",
    "print_fold_summary(fold_mae_list, fold_r2_train_list, fold_r2_test_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
