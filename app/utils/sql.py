from sqlalchemy import create_engine, text
from datetime import datetime, date
import pandas as pd
import os
import sqlite3


# ===============================
# ğŸ“¥ SQLiteã‹ã‚‰å…ƒãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
# ===============================
def load_data_from_sqlite(
    db_path: str = "/work/app/data/factory_manage/weight_data.db",
) -> pd.DataFrame:
    engine = create_engine(f"sqlite:///{db_path}")
    query = """
        SELECT ä¼ç¥¨æ—¥ä»˜, å“å, æ­£å‘³é‡é‡
        FROM ukeire
        WHERE ä¼ç¥¨æ—¥ä»˜ IS NOT NULL AND å“å IS NOT NULL AND æ­£å‘³é‡é‡ IS NOT NULL
    """
    df = pd.read_sql(query, engine)
    df["ä¼ç¥¨æ—¥ä»˜"] = pd.to_datetime(df["ä¼ç¥¨æ—¥ä»˜"], errors="coerce")
    df["æ­£å‘³é‡é‡"] = pd.to_numeric(df["æ­£å‘³é‡é‡"], errors="coerce")
    return df.dropna()


# ===============================
# ğŸ“… ä¼ç¥¨æ—¥ä»˜ã®æœ€å°ãƒ»æœ€å¤§ã‚’å–å¾—ã™ã‚‹
# ===============================
def get_date_range_from_sqlite(db_path: str) -> tuple[str, str]:
    engine = create_engine(f"sqlite:///{db_path}")
    with engine.connect() as conn:
        result = conn.execute(
            text("SELECT MIN(ä¼ç¥¨æ—¥ä»˜), MAX(ä¼ç¥¨æ—¥ä»˜) FROM ukeire")
        ).fetchone()
        return result[0], result[1]  # SQLiteã¯datetimeæ–‡å­—åˆ—ã§è¿”ã™


def get_training_date_range(
    db_path: str, table_name: str = "ukeire"
) -> tuple[date, date]:
    """
    ä»»æ„ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ä¼ç¥¨æ—¥ä»˜ã®æœ€å°ãƒ»æœ€å¤§ã‚’å–å¾—ã—ã€datetime.dateå‹ã§è¿”ã™
    """
    engine = create_engine(f"sqlite:///{db_path}")
    with engine.connect() as conn:
        result = conn.execute(
            text(f"SELECT MIN(ä¼ç¥¨æ—¥ä»˜), MAX(ä¼ç¥¨æ—¥ä»˜) FROM {table_name}")
        ).fetchone()
        if result is None:
            raise ValueError("ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        start_str, end_str = result

    start = datetime.strptime(start_str, "%Y-%m-%d %H:%M:%S").date()
    end = datetime.strptime(end_str, "%Y-%m-%d %H:%M:%S").date()

    return start, end


import os
import sqlite3
import pandas as pd
from sqlite3 import OperationalError


def save_df_to_sqlite_unique(df: pd.DataFrame, db_path: str, table_name: str) -> None:
    """
    SQLiteã«DataFrameã‚’ä¿å­˜ï¼ˆå…¨ã‚«ãƒ©ãƒ ã§é‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚’è¡Œã„ã€æ–°è¦è¡Œã®ã¿ã‚’è¿½è¨˜ï¼‰ã€‚

    ã‚¹ãƒ†ãƒƒãƒ—ï¼š
    1. DBã«ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã€æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
    2. dfã¨æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å…¨ã‚«ãƒ©ãƒ ã§æ¯”è¼ƒã—ã€é‡è¤‡è¡Œã‚’é™¤å¤–
    3. æ–°è¦ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã¿ã‚’SQLiteã«appendä¿å­˜
    """

    def convert_datetime_to_str(df: pd.DataFrame) -> pd.DataFrame:
        for col in df.select_dtypes(include=["datetime64[ns]"]).columns:
            df[col] = df[col].dt.strftime("%Y-%m-%d")
        return df

    def convert_nan_to_none(df: pd.DataFrame) -> pd.DataFrame:
        return df.where(pd.notnull(df), None)

    def load_existing_data(conn, table_name: str, expected_columns) -> pd.DataFrame:
        try:
            # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
            tables = pd.read_sql(
                "SELECT name FROM sqlite_master WHERE type='table';", conn
            )["name"].tolist()

            if table_name not in tables:
                print(
                    f"ğŸ“‚ ãƒ†ãƒ¼ãƒ–ãƒ« '{table_name}' ã¯å­˜åœ¨ã—ãªã„ãŸã‚ã€æ–°è¦ä½œæˆå¯¾è±¡ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚"
                )
                return pd.DataFrame(columns=expected_columns)

            # ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å…¨ä»¶èª­ã¿è¾¼ã¿
            return pd.read_sql(f"SELECT * FROM {table_name}", conn)

        except Exception as e:
            print(f"âŒ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            raise

    conn = None
    try:
        # --- ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆï¼ˆãªã‘ã‚Œã°ä½œã‚‹ï¼‰ ---
        os.makedirs(os.path.dirname(db_path), exist_ok=True)

        # --- SQLiteæ¥ç¶š ---
        conn = sqlite3.connect(db_path)

        # --- æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ---
        existing_df = load_existing_data(conn, table_name, df.columns)

        # --- datetime â†’ æ–‡å­—åˆ—, NaN â†’ None ã«å¤‰æ› ---
        df = convert_datetime_to_str(df)
        existing_df = convert_datetime_to_str(existing_df)
        df = convert_nan_to_none(df)
        existing_df = convert_nan_to_none(existing_df)

        # --- é‡è¤‡æ’é™¤ï¼šdfã«ã—ã‹å­˜åœ¨ã—ãªã„è¡Œã‚’æŠ½å‡º ---
        if not existing_df.empty:
            merged = df.merge(existing_df.drop_duplicates(), how="left", indicator=True)
            new_records = merged[merged["_merge"] == "left_only"].drop(
                columns=["_merge"]
            )
        else:
            new_records = df.copy()

        # --- ä¿å­˜å¯¾è±¡ã®ç¢ºèª ---
        if new_records.empty:
            print("âš ï¸ ä¿å­˜å¯¾è±¡ã®æ–°è¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆã™ã¹ã¦æ—¢å­˜ã¨é‡è¤‡ï¼‰")
            return

        # --- SQLiteã¸è¿½è¨˜ä¿å­˜ ---
        new_records.to_sql(name=table_name, con=conn, if_exists="append", index=False)
        print(f"âœ… æ–°è¦ {len(new_records)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

    except Exception as e:
        print(f"âŒ SQLiteä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    finally:
        if conn:
            conn.close()
