import streamlit as st
import pandas as pd
from utils.config_loader import get_path_from_yaml
from utils.get_holydays import get_japanese_holidays
from logic.factory_manage.predict_model_ver2 import (
    train_and_predict_with_holiday,
)
from components.custom_button import centered_button
from logic.manage.utils.upload_handler import handle_uploaded_files
from utils.config_loader import load_factory_required_files
from utils.check_uploaded_csv import (
    render_csv_upload_section,
    check_single_file_uploaded,
)
from logic.factory_manage.make_df import make_sql_db, make_csv
from logic.factory_manage.sql import load_data_from_sqlite


def csv_controller():
    """
    Streamlitä¸Šã§CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã€
    åŠ å·¥ãƒ»ä¿å­˜å‡¦ç†ã‚’è¡Œã†ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã€‚
    """
    selected_template = "inbound_volume"

    # --- å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ¼ã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾— ---
    required_keys = load_factory_required_files()[selected_template]

    # --- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰UIè¡¨ç¤ºï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«å¿œã˜ãŸãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ï¼‰ ---
    csv_file_type = "receive"
    render_csv_upload_section(csv_file_type)

    # --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ ---
    uploaded_files = handle_uploaded_files(required_keys)
    uploaded_file = uploaded_files.get(csv_file_type)
    all_uploaded, missing_key = check_single_file_uploaded(uploaded_file, csv_file_type)
    print(all_uploaded, missing_key)

    if all_uploaded:
        st.success("âœ… å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒã™ã¹ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸï¼")
        st.markdown("---")

        if centered_button("â© CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"):
            # --- CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ãƒ»æ•´å½¢ ---
            df = pd.read_csv(uploaded_file)
            df = make_csv(df)

            # --- SQLite DBã«ä¿å­˜ ---
            make_sql_db(df)

            # --- å®Œäº†é€šçŸ¥ã¨UIãƒªã‚»ãƒƒãƒˆ ---
            st.success("ğŸ“¥ CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¨ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            st.toast("CSVå‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ", icon="ğŸ“")

            # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æƒ…å ±ã‚’å‰Šé™¤ã—å†æç”» ---
            key_to_clear = f"uploaded_{csv_file_type}"
            if key_to_clear in st.session_state:
                del st.session_state[key_to_clear]

            st.rerun()


def predict_hannyu_ryou_controller(start_date, end_date):
    """
    æ¬å…¥é‡äºˆæ¸¬ã®ãŸã‚ã®å‡¦ç†ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã€‚

    - éå»ã®è¤‡æ•°å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€çµ±åˆãƒ»æ•´å½¢
    - æŒ‡å®šæœŸé–“ã«å¯¾ã™ã‚‹ç¥æ—¥æƒ…å ±ã®å–å¾—
    - å­¦ç¿’ãƒ»äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ã®å‘¼ã³å‡ºã—ï¼ˆtrain_and_predict_with_holidayï¼‰

    Parameters:
        start_date (date): äºˆæ¸¬å¯¾è±¡ã®é–‹å§‹æ—¥
        end_date (date): äºˆæ¸¬å¯¾è±¡ã®çµ‚äº†æ—¥

    Returns:
        pd.DataFrame: äºˆæ¸¬çµæœã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    # --- ãƒ‡ãƒ¼ã‚¿å–å¾— ---
    # csvã‹ã‚‰
    df_raw = read_csv_controller()

    # SQLã‹ã‚‰
    # df_raw = load_data_from_sqlite()

    # --- ç¥æ—¥ãƒ‡ãƒ¼ã‚¿å–å¾— ---
    holidays = get_japanese_holidays(start=start_date, end=end_date, as_str=True)

    # --- äºˆæ¸¬å®Ÿè¡Œ ---
    df_result = train_and_predict_with_holiday(
        df_raw, str(start_date), str(end_date), holidays
    )
    return df_result


def read_csv_controller():
    """
    æ¬å…¥é‡äºˆæ¸¬ã«å¿…è¦ãªCSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§çµ±åˆãƒ»æ•´å½¢ã™ã‚‹é–¢æ•°ã€‚

    Returns:
        pd.DataFrame: æ•´å½¢æ¸ˆã¿ã®æ¬å…¥ãƒ‡ãƒ¼ã‚¿ï¼ˆåˆ—: ä¼ç¥¨æ—¥ä»˜ãƒ»å“åãƒ»æ­£å‘³é‡é‡ï¼‰
    """

    # --- ãƒ‡ãƒ¼ã‚¿å–å¾— ---
    base_dir = get_path_from_yaml("input", section="directories")

    # --- æ–°ãƒ‡ãƒ¼ã‚¿ ---
    df_raw = pd.read_csv(f"{base_dir}/20240501-20250422.csv", encoding="utf-8")[
        ["ä¼ç¥¨æ—¥ä»˜", "æ­£å‘³é‡é‡", "å“å"]
    ]

    # --- æ—§ãƒ‡ãƒ¼ã‚¿ï¼ˆè¤‡æ•°å¹´ï¼‰ ---
    df_2020 = pd.read_csv(f"{base_dir}/2020é¡§å®¢.csv")[
        ["ä¼ç¥¨æ—¥ä»˜", "å•†å“", "æ­£å‘³é‡é‡_æ˜ç´°"]
    ]
    df_2021 = pd.read_csv(f"{base_dir}/2021é¡§å®¢.csv")[
        ["ä¼ç¥¨æ—¥ä»˜", "å•†å“", "æ­£å‘³é‡é‡_æ˜ç´°"]
    ]
    df_2023 = pd.read_csv(f"{base_dir}/2023_all.csv", low_memory=False)[
        ["ä¼ç¥¨æ—¥ä»˜", "å•†å“", "æ­£å‘³é‡é‡_æ˜ç´°"]
    ]

    # --- çµ±åˆãƒ»æ•´å½¢å‡¦ç† ---
    df_all = pd.concat([df_2020, df_2021, df_2023])
    df_all["ä¼ç¥¨æ—¥ä»˜"] = pd.to_datetime(df_all["ä¼ç¥¨æ—¥ä»˜"])
    df_all.rename(columns={"å•†å“": "å“å", "æ­£å‘³é‡é‡_æ˜ç´°": "æ­£å‘³é‡é‡"}, inplace=True)
    df_raw = pd.concat([df_raw, df_all])

    # --- æ—¥ä»˜ãƒ»é‡é‡ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° ---
    df_raw["ä¼ç¥¨æ—¥ä»˜"] = df_raw["ä¼ç¥¨æ—¥ä»˜"].str.replace(r"\(.*\)", "", regex=True)
    df_raw["ä¼ç¥¨æ—¥ä»˜"] = pd.to_datetime(df_raw["ä¼ç¥¨æ—¥ä»˜"], errors="coerce")
    df_raw["æ­£å‘³é‡é‡"] = pd.to_numeric(df_raw["æ­£å‘³é‡é‡"], errors="coerce")
    df_raw = df_raw.dropna(subset=["æ­£å‘³é‡é‡"])

    return df_raw
