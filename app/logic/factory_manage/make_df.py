import pandas as pd
import os
from utils.get_holydays import get_japanese_holidays
from logic.factory_manage.sql import save_df_to_sqlite_unique
from utils.config_loader import get_path_from_yaml
from utils.cleaners import enforce_dtypes, strip_whitespace
from utils.config_loader import get_expected_dtypes_by_template
from logic.factory_manage.original import maesyori


def make_sql_old():
    """
    éå»ã®è¤‡æ•°å¹´åˆ†ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€
    æ—¥ä»˜ã‚„æ•°å€¤æ•´å½¢ã€ä¸è¦ãƒ‡ãƒ¼ã‚¿ã®é™¤å¤–ã€ç¥æ—¥ãƒ•ãƒ©ã‚°ä»˜ä¸ã‚’è¡Œã„ã€
    SQLiteã«çµ±åˆä¿å­˜ã™ã‚‹ãƒ¡ã‚¤ãƒ³é–¢æ•°ã€‚
    """
    base_dir = get_path_from_yaml("input", section="directories")

    # ãƒ‡ãƒ¼ã‚¿èª­è¾¼
    # df_raw = read_csv_hannnyuu_old()
    df_raw = maesyori()

    # --- ç¥æ—¥ãƒ•ãƒ©ã‚°ä»˜ä¸ ---
    start_date = df_raw["ä¼ç¥¨æ—¥ä»˜"].min().date()
    end_date = df_raw["ä¼ç¥¨æ—¥ä»˜"].max().date()
    print(f"ğŸ” df2_min_max: {start_date} ï½ {end_date}")
    holidays = get_japanese_holidays(start=start_date, end=end_date, as_str=False)
    holiday_set = set(holidays)

    df_raw["ç¥æ—¥ãƒ•ãƒ©ã‚°"] = df_raw["ä¼ç¥¨æ—¥ä»˜"].dt.date.apply(
        lambda x: 1 if x in holiday_set else 0
    )
    print("ğŸŒ ç¥æ—¥ãƒ•ãƒ©ã‚°ä»˜ä¸å®Œäº†")

    # --- SQLiteä¿å­˜ ---
    try:
        db_path = get_path_from_yaml("weight_data", section="sql_database")
        save_df_to_sqlite_unique(df=df_raw, db_path=db_path, table_name="ukeire")
        print("âœ… SQLiteä¿å­˜å®Œäº†")
    except Exception as e:
        print(f"âŒ SQLiteä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    return df_raw


def make_sql_db(df: pd.DataFrame):
    """
    ä¸ãˆã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ç„¡åŠ¹ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã€
    æ•´å½¢ãƒ»ç¥æ—¥ä»˜ä¸ã‚’ã—ã¦SQLiteã«ä¿å­˜ã™ã‚‹ã€‚

    Args:
        df (pd.DataFrame): å…ƒãƒ‡ãƒ¼ã‚¿
    """
    print(f"ğŸ” å…ƒãƒ‡ãƒ¼ã‚¿ã®è¡Œæ•°: {len(df)}")

    df["ä¼ç¥¨æ—¥ä»˜"] = df["ä¼ç¥¨æ—¥ä»˜"].astype(str).str.replace(r"\(.*\)", "", regex=True)
    df["ä¼ç¥¨æ—¥ä»˜"] = pd.to_datetime(df["ä¼ç¥¨æ—¥ä»˜"], errors="coerce")
    df["æ­£å‘³é‡é‡"] = pd.to_numeric(df["æ­£å‘³é‡é‡"], errors="coerce")

    dropped_rows = df[df[["ä¼ç¥¨æ—¥ä»˜", "æ­£å‘³é‡é‡"]].isna().any(axis=1)]
    dropped_rows.to_csv("dropped_rows.csv", index=False)

    df = df.dropna(subset=["æ­£å‘³é‡é‡", "ä¼ç¥¨æ—¥ä»˜"])
    print(f"ğŸ” dropnaå¾Œã®è¡Œæ•°: {len(df)}")

    df = df[df["æ­£å‘³é‡é‡"] != 0]
    print(f"ğŸ” æ­£å‘³é‡é‡â‰ 0 ã®è¡Œæ•°: {len(df)}")

    start_date = df["ä¼ç¥¨æ—¥ä»˜"].min().date()
    end_date = df["ä¼ç¥¨æ—¥ä»˜"].max().date()
    holidays = get_japanese_holidays(start=start_date, end=end_date, as_str=False)
    holiday_set = set(holidays)
    df["ç¥æ—¥ãƒ•ãƒ©ã‚°"] = df["ä¼ç¥¨æ—¥ä»˜"].dt.date.apply(
        lambda x: 1 if x in holiday_set else 0
    )

    df = df.loc[:, ["ä¼ç¥¨æ—¥ä»˜", "æ­£å‘³é‡é‡", "å“å", "ç¥æ—¥ãƒ•ãƒ©ã‚°"]]
    print(f"ğŸ” æ•´å½¢å¾Œã®è¡Œæ•°: {len(df)}")

    try:
        db_path = get_path_from_yaml("weight_data", section="sql_database")
        save_df_to_sqlite_unique(
            df=df,
            db_path=db_path,
            table_name="ukeire",
        )
    except Exception as e:
        print(f"âŒ SQLiteä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


def make_csv(df: pd.DataFrame) -> pd.DataFrame:
    """
    ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«åŸºã¥ã„ã¦å—å…¥ãƒ‡ãƒ¼ã‚¿ã®ç©ºç™½é™¤å»ãƒ»å‹å¤‰æ›ã‚’è¡Œã†ã€‚

    Args:
        df (pd.DataFrame): å…ƒãƒ‡ãƒ¼ã‚¿

    Returns:
        pd.DataFrame: æ•´å½¢æ¸ˆãƒ‡ãƒ¼ã‚¿
    """
    df = strip_whitespace(df)
    expected_dtypes = get_expected_dtypes_by_template("inbound_volume")
    dtypes = expected_dtypes.get("receive", {})

    if dtypes:
        df = enforce_dtypes(df, dtypes)

    return df


def read_csv_hannnyuu():
    """
    æ¬å…¥é‡äºˆæ¸¬ã«å¿…è¦ãªCSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§çµ±åˆãƒ»æ•´å½¢ã™ã‚‹é–¢æ•°ã€‚

    Returns:
        pd.DataFrame: æ•´å½¢æ¸ˆã¿ã®æ¬å…¥ãƒ‡ãƒ¼ã‚¿ï¼ˆåˆ—: ä¼ç¥¨æ—¥ä»˜ãƒ»å“åãƒ»æ­£å‘³é‡é‡ï¼‰
    """
    # --- ãƒ‡ãƒ¼ã‚¿å–å¾— ---
    base_dir = get_path_from_yaml("input", section="directories")

    # --- æ–°ãƒ‡ãƒ¼ã‚¿ï¼ˆ2024ï½2025ï¼‰ ---
    df_new = pd.read_csv(f"{base_dir}/20240501-20250422.csv", encoding="utf-8")[
        ["ä¼ç¥¨æ—¥ä»˜", "æ­£å‘³é‡é‡", "å“å"]
    ]
    df_new["ä¼ç¥¨æ—¥ä»˜"] = df_new["ä¼ç¥¨æ—¥ä»˜"].str.replace(r"\(.*\)", "", regex=True)
    df_new["ä¼ç¥¨æ—¥ä»˜"] = pd.to_datetime(df_new["ä¼ç¥¨æ—¥ä»˜"], errors="coerce")

    # --- æ—§ãƒ‡ãƒ¼ã‚¿ï¼ˆ2020ã€œ2023ï¼‰ ---
    df_2020 = pd.read_csv(f"{base_dir}/2020é¡§å®¢.csv")[
        ["ä¼ç¥¨æ—¥ä»˜", "å•†å“", "æ­£å‘³é‡é‡_æ˜ç´°"]
    ]
    df_2021 = pd.read_csv(f"{base_dir}/2021é¡§å®¢.csv")[
        ["ä¼ç¥¨æ—¥ä»˜", "å•†å“", "æ­£å‘³é‡é‡_æ˜ç´°"]
    ]
    df_2022 = pd.read_csv(f"{base_dir}/2022é¡§å®¢.csv")[
        ["ä¼ç¥¨æ—¥ä»˜", "å•†å“", "æ­£å‘³é‡é‡_æ˜ç´°"]
    ]
    df_2023 = pd.read_csv(f"{base_dir}/2023_all.csv", low_memory=False)[
        ["ä¼ç¥¨æ—¥ä»˜", "å•†å“", "æ­£å‘³é‡é‡_æ˜ç´°"]
    ]
    df_old = pd.concat([df_2020, df_2021, df_2022, df_2023], ignore_index=True)
    df_old.rename(columns={"å•†å“": "å“å", "æ­£å‘³é‡é‡_æ˜ç´°": "æ­£å‘³é‡é‡"}, inplace=True)
    df_old["ä¼ç¥¨æ—¥ä»˜"] = pd.to_datetime(df_old["ä¼ç¥¨æ—¥ä»˜"], errors="coerce")

    # --- çµåˆã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° ---
    df_all = pd.concat([df_new, df_old], ignore_index=True)
    df_all["æ­£å‘³é‡é‡"] = pd.to_numeric(df_all["æ­£å‘³é‡é‡"], errors="coerce")
    df_all = df_all.dropna(subset=["æ­£å‘³é‡é‡", "ä¼ç¥¨æ—¥ä»˜"])

    # --- ç¢ºèªå‡ºåŠ› ---
    start_date = df_all["ä¼ç¥¨æ—¥ä»˜"].min().date()
    end_date = df_all["ä¼ç¥¨æ—¥ä»˜"].max().date()
    print(f"ğŸ” df1_min_max: {start_date} ï½ {end_date}")

    return df_all


def read_csv_hannnyuu_old():
    base_dir = get_path_from_yaml("input", section="directories")
    df_raw = pd.read_csv(f"{base_dir}/20240501-20250422.csv", encoding="utf-8")
    df_raw = df_raw[["ä¼ç¥¨æ—¥ä»˜", "æ­£å‘³é‡é‡", "å“å"]]
    df_raw["ä¼ç¥¨æ—¥ä»˜"] = df_raw["ä¼ç¥¨æ—¥ä»˜"].str.replace(r"\(.*\)", "", regex=True)
    df_raw["ä¼ç¥¨æ—¥ä»˜"] = pd.to_datetime(df_raw["ä¼ç¥¨æ—¥ä»˜"], errors="coerce")

    df_2020 = pd.read_csv(f"{base_dir}/2020é¡§å®¢.csv")

    df_2021 = pd.read_csv(f"{base_dir}/2021é¡§å®¢.csv")

    df_2023 = pd.read_csv(f"{base_dir}/2023_all.csv")

    df_2020 = df_2020[["ä¼ç¥¨æ—¥ä»˜", "å•†å“", "æ­£å‘³é‡é‡_æ˜ç´°"]]

    df_2021 = df_2021[["ä¼ç¥¨æ—¥ä»˜", "å•†å“", "æ­£å‘³é‡é‡_æ˜ç´°"]]

    df_2023 = df_2023[["ä¼ç¥¨æ—¥ä»˜", "å•†å“", "æ­£å‘³é‡é‡_æ˜ç´°"]]

    df_all = pd.concat([df_2020, df_2021, df_2023])

    df_all["ä¼ç¥¨æ—¥ä»˜"] = pd.to_datetime(df_all["ä¼ç¥¨æ—¥ä»˜"])

    df_all.rename(columns={"å•†å“": "å“å", "æ­£å‘³é‡é‡_æ˜ç´°": "æ­£å‘³é‡é‡"}, inplace=True)

    df_raw = pd.concat([df_raw, df_all])

    return df_all


# --- å®Ÿè¡Œ ---
if __name__ == "__main__":
    make_sql_old()
