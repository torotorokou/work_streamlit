import pandas as pd
from logic.models.csv_processor import process_csv_by_date, check_date_alignment
from components.ui_message import (
    show_warning,
    show_error,
    show_date_mismatch,
)
from utils.file_loader import load_uploaded_csv_files
from utils.cleaners import enforce_dtypes, strip_whitespace
from utils.config_loader import get_expected_dtypes_by_template
from utils.logger import app_logger


def apply_expected_dtypes(
    dfs: dict[str, pd.DataFrame],
    template_key: str,
) -> dict[str, pd.DataFrame]:
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå„CSVã«å¯¾ã—ã¦ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå®šç¾©ã«åŸºã¥ããƒ‡ãƒ¼ã‚¿å‹ã‚’å¼·åˆ¶é©ç”¨ã™ã‚‹ã€‚

    Parameters
    ----------
    dfs : dict[str, pd.DataFrame]
        èª­ã¿è¾¼ã‚“ã CSVãƒ•ã‚¡ã‚¤ãƒ«ç¾¤
    template_key : str
        ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåï¼ˆä¾‹: average_sheetï¼‰

    Returns
    -------
    dict[str, pd.DataFrame]
        å‹å¼·åˆ¶å¾Œã®DataFrameç¾¤
    """
    logger = app_logger()
    expected_dtypes_per_file = get_expected_dtypes_by_template(template_key)

    for key in dfs:
        dfs[key] = strip_whitespace(dfs[key])  # ğŸ”½ ç©ºç™½é™¤å»

        dtypes = expected_dtypes_per_file.get(key)
        if dtypes:
            dfs[key] = enforce_dtypes(dfs[key], dtypes)
            logger.info(f"âœ… å‹ã‚’é©ç”¨ã—ã¾ã—ãŸ: {key}")

    return dfs


def prepare_csv_data(
    uploaded_files: dict, date_columns: dict, template_key: str
) -> dict:
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€å‹ã‚’é©ç”¨ã—ã€
    æ—¥ä»˜ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯ã—ãŸã†ãˆã§ã€å‡¦ç†å¯¾è±¡ã®DataFrameç¾¤ã‚’è¿”ã™ã€‚

    Parameters:
        uploaded_files (dict): {key: csvãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹} ã®è¾æ›¸
        date_columns (dict): {key: æ—¥ä»˜åˆ—å} ã®è¾æ›¸
        template_key (str): ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè­˜åˆ¥å­ï¼ˆå‹é©ç”¨ãªã©ã«ä½¿ç”¨ï¼‰

    Returns:
        tuple[dict[str, DataFrame], list[str]]: å„ã‚­ãƒ¼ã«å¯¾å¿œã™ã‚‹æ•´å½¢æ¸ˆã¿DataFrameç¾¤ã¨ã€å…±é€šæ—¥ä»˜ãƒªã‚¹ãƒˆ
        â€» æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºã®dictã‚’è¿”ã™
    """
    logger = app_logger()
    logger.info("ğŸ“„ ã“ã‚Œã‹ã‚‰CSVã®æ›¸é¡ã‚’ä½œæˆã—ã¾ã™...")

    # --- â‘  ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆDataFrameåŒ–ï¼‰ ---
    dfs = load_uploaded_csv_files(uploaded_files)

    # --- â‘¡ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«å¿œã˜ãŸå‹å¤‰æ›ã‚’å®Ÿæ–½ï¼ˆæ–‡å­—åˆ—â†’æ•°å€¤ãƒ»æ—¥ä»˜ãªã©ï¼‰ ---
    dfs = apply_expected_dtypes(dfs, template_key)

    logger.info("ğŸ“„ CSVã®æ—¥ä»˜ã‚’ç¢ºèªä¸­ã§ã™...")

    # --- â‘¢ å„CSVã«ãŠã„ã¦ã€æ—¥ä»˜åˆ—ã®å­˜åœ¨ã¨å†…å®¹ã‚’ç¢ºèª ---
    for key, df in dfs.items():
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§å®šç¾©ã•ã‚ŒãŸæ—¥ä»˜åˆ—åã‚’å–å¾—
        date_col = date_columns.get(key)

        # æ—¥ä»˜åˆ—å®šç¾©ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯è­¦å‘Šã‚’è¡¨ç¤ºã—ã¦ä¸­æ–­
        if not date_col:
            show_warning(f"âš ï¸ {key} ã®æ—¥ä»˜ã‚«ãƒ©ãƒ å®šç¾©ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
            return {}

        # å®Ÿéš›ã®CSVã«æ—¥ä»˜åˆ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã‚‚ä¸­æ–­
        if date_col not in df.columns:
            show_warning(f"âš ï¸ {key} ã®CSVã«ã€Œ{date_col}ã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return {}

        # æ—¥ä»˜åˆ—ã‚’åŸºæº–ã¨ã—ãŸå‡¦ç†ï¼ˆä¸¦ã³æ›¿ãˆãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãªã©ï¼‰ã‚’å®Ÿæ–½
        dfs[key] = process_csv_by_date(df, date_col)

    # --- â‘£ å„CSVé–“ã§æ—¥ä»˜ã®æ•´åˆæ€§ï¼ˆå…±é€šã®æ—¥ä»˜ãŒã‚ã‚‹ã‹ï¼‰ã‚’ãƒã‚§ãƒƒã‚¯ ---
    result = check_date_alignment(dfs, date_columns)
    if not result["status"]:
        # æ•´åˆæ€§NGæ™‚ï¼šã‚¨ãƒ©ãƒ¼è¡¨ç¤ºã¨è©³ç´°å†…å®¹ã®æç¤º
        show_error(result["error"])
        if "details" in result:
            show_date_mismatch(result["details"])
        return {}

    logger.info(f"âœ… ã™ã¹ã¦ã®CSVã§æ—¥ä»˜ãŒä¸€è‡´ã—ã¦ã„ã¾ã™ï¼š{result['dates']}")

    # --- â‘¤ æ­£å¸¸çµ‚äº†ï¼šæ•´å½¢æ¸ˆã¿DataFrameã¨æ—¥ä»˜ä¸€è¦§ã‚’è¿”ã™ ---
    return dfs, result["dates"]
