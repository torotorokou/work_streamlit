import pandas as pd
from logic.models.csv_processor import process_csv_by_date, check_date_alignment
from components.ui_message import (
    show_warning,
    show_error,
    show_date_mismatch,
)
from utils.file_loader import load_uploaded_csv_files
from utils.cleaners import enforce_dtypes, strip_whitespace
from utils.config_loader import get_expected_dtypes_by_template
from utils.logger import app_logger


def apply_expected_dtypes(
    dfs: dict[str, pd.DataFrame],
    template_key: str,
) -> dict[str, pd.DataFrame]:
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå„CSVã«å¯¾ã—ã¦ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå®šç¾©ã«åŸºã¥ããƒ‡ãƒ¼ã‚¿å‹ã‚’å¼·åˆ¶é©ç”¨ã™ã‚‹ã€‚

    Parameters
    ----------
    dfs : dict[str, pd.DataFrame]
        èª­ã¿è¾¼ã‚“ã CSVãƒ•ã‚¡ã‚¤ãƒ«ç¾¤
    template_key : str
        ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåï¼ˆä¾‹: average_sheetï¼‰

    Returns
    -------
    dict[str, pd.DataFrame]
        å‹å¼·åˆ¶å¾Œã®DataFrameç¾¤
    """
    logger = app_logger()
    expected_dtypes_per_file = get_expected_dtypes_by_template(template_key)

    for key in dfs:
        dfs[key] = strip_whitespace(dfs[key])  # ğŸ”½ ç©ºç™½é™¤å»

        dtypes = expected_dtypes_per_file.get(key)
        if dtypes:
            dfs[key] = enforce_dtypes(dfs[key], dtypes)
            logger.info(f"âœ… å‹ã‚’é©ç”¨ã—ã¾ã—ãŸ: {key}")

    return dfs


def prepare_csv_data(
    uploaded_files: dict, date_columns: dict, template_key: str
) -> dict:
    logger = app_logger()
    logger.info("ğŸ“„ ã“ã‚Œã‹ã‚‰CSVã®æ›¸é¡ã‚’ä½œæˆã—ã¾ã™...")

    dfs = load_uploaded_csv_files(uploaded_files)

    # å‹é©ç”¨å‡¦ç†ã‚’ç‹¬ç«‹é–¢æ•°ã§å®Ÿæ–½
    dfs = apply_expected_dtypes(dfs, template_key)

    logger.info("ğŸ“„ CSVã®æ—¥ä»˜ã‚’ç¢ºèªä¸­ã§ã™...")

    for key, df in dfs.items():
        date_col = date_columns.get(key)

        if not date_col:
            show_warning(f"âš ï¸ {key} ã®æ—¥ä»˜ã‚«ãƒ©ãƒ å®šç¾©ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
            return {}

        if date_col not in df.columns:
            show_warning(f"âš ï¸ {key} ã®CSVã«ã€Œ{date_col}ã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return {}

        dfs[key] = process_csv_by_date(df, date_col)

    result = check_date_alignment(dfs, date_columns)
    if not result["status"]:
        show_error(result["error"])
        if "details" in result:
            show_date_mismatch(result["details"])
        return {}

    logger.info(f"âœ… ã™ã¹ã¦ã®CSVã§æ—¥ä»˜ãŒä¸€è‡´ã—ã¦ã„ã¾ã™ï¼š{result['dates']}")
    return dfs, result["dates"]
