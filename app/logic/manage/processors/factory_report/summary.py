import pandas as pd
from utils.logger import app_logger
from logic.manage.utils.summary_tools import safe_merge_by_keys, summary_update_column_if_notna


# --- utils/filters.py ---
def apply_negation_filters(
    df: pd.DataFrame, match_df: pd.DataFrame, key_cols: list[str], logger=None
) -> pd.DataFrame:
    """
    match_df ã® key_cols ã« `Notå€¤` ã¾ãŸã¯ `NOTå€¤` ãŒã‚ã‚Œã°ã€ãã®å€¤ã‚’é™¤å¤–ã™ã‚‹ãƒ•ã‚£ãƒ«ã‚¿ã‚’ df ã«é©ç”¨ã€‚
    """
    filter_conditions = {}
    for col in key_cols:
        if col not in df.columns:
            if logger:
                logger.warning(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ã«åˆ— '{col}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue

        unique_vals = match_df[col].dropna().unique()
        neg_vals = [
            v[3:] for v in unique_vals
            if isinstance(v, str) and v.lower().startswith("not")
        ]
        if neg_vals:
            filter_conditions[col] = neg_vals
            if logger:
                logger.info(
                    f"ğŸš« '{col}' ã«å¯¾ã—ã¦å¦å®šãƒ•ã‚£ãƒ«ã‚¿: {', '.join(neg_vals)} ã‚’é©ç”¨ã—ã¾ã—ãŸ"
                )

    for col, ng_values in filter_conditions.items():
        df = df[~df[col].isin(ng_values)]

    return df


# --- processors/summary.py ---
def process_sheet_partition(
    master_csv: pd.DataFrame, sheet_name: str, expected_level: int, logger=None
) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    æŒ‡å®šã‚·ãƒ¼ãƒˆã‹ã‚‰ key_level ä¸€è‡´è¡Œã¨ä¸ä¸€è‡´è¡Œã‚’åˆ†é›¢ã€‚
    """
    sheet_df = master_csv[master_csv["CSVã‚·ãƒ¼ãƒˆå"] == sheet_name].copy()

    if "key_level" not in sheet_df.columns:
        if logger:
            logger.warning("âŒ key_levelåˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return pd.DataFrame(), pd.DataFrame()

    try:
        match_df = sheet_df[sheet_df["key_level"].astype(int) == expected_level].copy()
        remain_df = sheet_df[sheet_df["key_level"].astype(int) != expected_level].copy()
        return match_df, remain_df
    except Exception as e:
        if logger:
            logger.error(f"âŒ key_levelå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        return pd.DataFrame(), pd.DataFrame()


def summary_apply_by_sheet(
    master_csv: pd.DataFrame,
    data_df: pd.DataFrame,
    sheet_name: str,
    key_cols: list[str],
    source_col: str = "æ­£å‘³é‡é‡",
    target_col: str = "å€¤",
) -> pd.DataFrame:
    """
    master_csv ã«å¯¾ã—ã€data_df ã‚’ key_cols ã§ groupby & sum ã—ã¦ãƒãƒ¼ã‚¸ã™ã‚‹ã€‚
    master_csv ã® key_level ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ã€ãŠã‚ˆã³ `Notå€¤` ã«ã‚ˆã‚‹ notæ¤œç´¢ã‚’ã‚µãƒãƒ¼ãƒˆã€‚
    `Notå€¤` ã‚’å«ã‚€åˆ—ã¯ãƒãƒ¼ã‚¸ã‚­ãƒ¼ã‹ã‚‰é™¤å¤–ã™ã‚‹ã€‚
    """
    logger = app_logger()
    logger.info(f"â–¶ï¸ ã‚·ãƒ¼ãƒˆ: {sheet_name}, ã‚­ãƒ¼: {key_cols}, é›†è¨ˆåˆ—: {source_col}")

    # --- è©²å½“ã‚·ãƒ¼ãƒˆã® key_level ãƒ•ã‚£ãƒ«ã‚¿ ---
    expected_level = len(key_cols)
    match_df, remain_df = process_sheet_partition(
        master_csv, sheet_name, expected_level, logger
    )

    if match_df.empty:
        logger.info(
            f"âš ï¸ key_level={expected_level} ã«ä¸€è‡´ã™ã‚‹è¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"
        )
        return master_csv

    # --- notæ¤œç´¢ã‚’é©ç”¨ï¼ˆNotå€¤ã®ã‚ã‚‹è¡Œã‚’é™¤å¤–ï¼‰ ---
    filtered_data_df = apply_negation_filters(
        data_df.copy(), match_df, key_cols, logger
    )

    # --- ãƒãƒ¼ã‚¸ç”¨ key ã‚’å†å®šç¾©ï¼ˆNotã€‡ã€‡ã‚’å«ã‚€åˆ—ã‚’é™¤å¤–ï¼‰ ---
    merge_key_cols = []
    for col in key_cols:
        if col in match_df.columns:
            has_neg = any(
                isinstance(val, str) and val.lower().startswith("not")
                for val in match_df[col].dropna().unique()
            )
            if not has_neg:
                merge_key_cols.append(col)
            else:
                logger.info(f"âš ï¸ '{col}' ã« 'Not' æŒ‡å®šãŒã‚ã‚‹ãŸã‚ãƒãƒ¼ã‚¸ã‚­ãƒ¼ã‹ã‚‰é™¤å¤–")

    if not merge_key_cols:
        logger.warning("âŒ æœ‰åŠ¹ãªãƒãƒ¼ã‚¸ã‚­ãƒ¼ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return master_csv

    # --- é›†è¨ˆ ---
    agg_df = filtered_data_df.groupby(merge_key_cols, as_index=False)[[source_col]].sum()

    # --- ãƒãƒ¼ã‚¸ ---
    merged_df = safe_merge_by_keys(match_df, agg_df, merge_key_cols)
    merged_df = summary_update_column_if_notna(merged_df, source_col, target_col)

    # --- æ­£å‘³é‡é‡ã®å‰Šé™¤ ---
    if source_col in merged_df.columns:
        merged_df.drop(columns=[source_col], inplace=True)

    # --- æœ€çµ‚çµåˆï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ã®ä»–ã‚·ãƒ¼ãƒˆ + æ®‹ä½™ + ãƒãƒ¼ã‚¸çµæœï¼‰---
    master_others = master_csv[master_csv["CSVã‚·ãƒ¼ãƒˆå"] != sheet_name]
    final_df = pd.concat([master_others, remain_df, merged_df], ignore_index=True)

    return final_df