from utils.config_loader import get_required_columns_definition
from utils.logger import app_logger


def load_filtered_dataframe(dfs, key, target_columns):
    """
    æŒ‡å®šã•ã‚ŒãŸè¾æ›¸å‹DataFrameã‹ã‚‰ã€å¯¾è±¡ã‚­ãƒ¼ã®DataFrameã‚’å–å¾—ã—ã€
    æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã®ã¿ã‚’æŠ½å‡ºã—ã¦è¿”ã™ã€‚
    YAMLå½¢å¼ã§å‹ä»˜ãã®dictã‚„ãƒã‚¹ãƒˆãƒªã‚¹ãƒˆã«ã‚‚å¯¾å¿œã€‚

    Parameters:
        dfs (dict): è¤‡æ•°ã®DataFrameã‚’æ ¼ç´ã—ãŸè¾æ›¸ã€‚ä¾‹: {"receive": df1, "yard": df2}
        key (str): å¯¾è±¡ã¨ãªã‚‹DataFrameã®ã‚­ãƒ¼åã€‚ä¾‹: "receive"
        target_columns (list or dict): æŠ½å‡ºã™ã‚‹ã‚«ãƒ©ãƒ åã®ãƒªã‚¹ãƒˆ or {ã‚«ãƒ©ãƒ å: å‹}

    Returns:
        pd.DataFrame: æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã®ã¿ã‚’æŒã¤DataFrameï¼ˆãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ï¼‰
    """
    logger = app_logger()

    if key not in dfs:
        raise KeyError(f"{key} ã¯dfsã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")

    df = dfs[key]

    # --- å‹ä»˜ãè¾æ›¸ã ã£ãŸã‚‰ã‚­ãƒ¼ã ã‘ã‚’ä½¿ã†
    if isinstance(target_columns, dict):
        target_columns = list(target_columns.keys())

    # --- listã®ä¸­èº«ãŒã•ã‚‰ã«listãªã‚‰ flattenï¼ˆ[[...]] â†’ [...]ï¼‰
    if (
        isinstance(target_columns, list)
        and target_columns
        and isinstance(target_columns[0], list)
    ):
        target_columns = target_columns[0]

    missing_cols = [col for col in target_columns if col not in df.columns]
    if missing_cols:
        logger.error(f"{key} ã«å¿…è¦ãªã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_cols}")
        raise ValueError(f"{key} ã«æ¬¡ã®ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {missing_cols}")

    return df[target_columns]


# utils/list_tools.py ãªã©ã«ç½®ã„ã¦ã‚‚OK
def flatten_list(nested_list):
    """
    1æ®µãƒã‚¹ãƒˆã•ã‚ŒãŸãƒªã‚¹ãƒˆã‚’ãƒ•ãƒ©ãƒƒãƒˆã«ã™ã‚‹ã€‚
    ä¾‹: [['A', 'B'], 'C'] â†’ ['A', 'B', 'C']
    """
    flat = []
    for item in nested_list:
        if isinstance(item, list):
            flat.extend(item)
        else:
            flat.append(item)
    return flat


def load_all_filtered_dataframes(
    dfs: dict,
    keys: list[str],
    template_name: str,
) -> dict:
    """
    æŒ‡å®šã•ã‚ŒãŸå¸³ç¥¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨CSVã‚­ãƒ¼ã«åŸºã¥ãã€å¿…è¦ãªã‚«ãƒ©ãƒ ã®ã¿æŠ½å‡ºã—ã¦è¿”ã™ã€‚
    """

    df_dict = {}
    column_defs = get_required_columns_definition(template_name)
    print(f"ğŸ” å¯¾è±¡ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {template_name}, ã‚«ãƒ©ãƒ å®šç¾©: {column_defs}")

    for key in keys:
        if key in dfs:
            target_columns = column_defs.get(key, [])
            # âœ… ãƒã‚¹ãƒˆã•ã‚Œã¦ã„ã‚‹å ´åˆã«å‚™ãˆã¦ flatten
            target_columns = flatten_list(target_columns)
            df_dict[key] = load_filtered_dataframe(dfs, key, target_columns)

    return df_dict
