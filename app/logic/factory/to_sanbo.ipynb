{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec9050c1-65da-40f8-9aca-508d54319c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple, List\n",
    "from sklearn.linear_model import Ridge, LogisticRegression, ElasticNet\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    GradientBoostingClassifier,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import joblib\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.linear_model import ElasticNet\n",
    "# from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "# from sklearn.model_selection import train_test_split, KFold\n",
    "# from sklearn.base import clone\n",
    "# from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71fd1ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ R² = 0.997, MAE = 1,380 kg\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "日付",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "予測値",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "補正後予測",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "下限95CI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "上限95CI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "判定ラベル",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "未満確率",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4638c7cf-8334-44c4-ae41-f4d5e3789ad0",
       "rows": [
        [
         "2024-05-08",
         "93846.73302879186",
         "93846.73302879186",
         "90354.10019287094",
         "97339.36586471277",
         "注意",
         "0.055"
        ],
        [
         "2024-05-09",
         "90126.6430319448",
         "90126.6430319448",
         "86634.01019602388",
         "93619.27586786571",
         "注意",
         "0.092"
        ],
        [
         "2024-05-10",
         "89483.6473964519",
         "89483.6473964519",
         "85991.01456053098",
         "92976.28023237281",
         "注意",
         "0.274"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>予測値</th>\n",
       "      <th>補正後予測</th>\n",
       "      <th>下限95CI</th>\n",
       "      <th>上限95CI</th>\n",
       "      <th>判定ラベル</th>\n",
       "      <th>未満確率</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>日付</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-05-08</th>\n",
       "      <td>93846.733029</td>\n",
       "      <td>93846.733029</td>\n",
       "      <td>90354.100193</td>\n",
       "      <td>97339.365865</td>\n",
       "      <td>注意</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-09</th>\n",
       "      <td>90126.643032</td>\n",
       "      <td>90126.643032</td>\n",
       "      <td>86634.010196</td>\n",
       "      <td>93619.275868</td>\n",
       "      <td>注意</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-10</th>\n",
       "      <td>89483.647396</td>\n",
       "      <td>89483.647396</td>\n",
       "      <td>85991.014561</td>\n",
       "      <td>92976.280232</td>\n",
       "      <td>注意</td>\n",
       "      <td>0.274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     予測値         補正後予測        下限95CI        上限95CI 判定ラベル  \\\n",
       "日付                                                                         \n",
       "2024-05-08  93846.733029  93846.733029  90354.100193  97339.365865    注意   \n",
       "2024-05-09  90126.643032  90126.643032  86634.010196  93619.275868    注意   \n",
       "2024-05-10  89483.647396  89483.647396  85991.014561  92976.280232    注意   \n",
       "\n",
       "             未満確率  \n",
       "日付                 \n",
       "2024-05-08  0.055  \n",
       "2024-05-09  0.092  \n",
       "2024-05-10  0.274  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_and_predict_with_holiday(\n",
    "    df_raw: pd.DataFrame, start_date: str, end_date: str, holidays: list[str]\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    # --- 前処理 ---\n",
    "    df_raw = df_raw.copy()\n",
    "    df_raw[\"伝票日付\"] = df_raw[\"伝票日付\"].str.replace(r\"\\(.*\\)\", \"\", regex=True)\n",
    "    df_raw[\"伝票日付\"] = pd.to_datetime(df_raw[\"伝票日付\"], errors=\"coerce\")\n",
    "    df_raw[\"正味重量\"] = pd.to_numeric(df_raw[\"正味重量\"], errors=\"coerce\")\n",
    "    df_raw = df_raw.dropna(subset=[\"正味重量\"])\n",
    "\n",
    "    df_pivot = (\n",
    "        df_raw.groupby([\"伝票日付\", \"品名\"])[\"正味重量\"].sum().unstack(fill_value=0)\n",
    "    )\n",
    "    df_pivot[\"合計\"] = df_pivot.sum(axis=1)\n",
    "\n",
    "    df_feat = pd.DataFrame(index=df_pivot.index)\n",
    "    df_feat[\"混合廃棄物A_前日\"] = df_pivot[\"混合廃棄物A\"].shift(1)\n",
    "    df_feat[\"混合廃棄物B_前日\"] = df_pivot[\"混合廃棄物B\"].shift(1)\n",
    "    df_feat[\"合計_前日\"] = df_pivot[\"合計\"].shift(1)\n",
    "    df_feat[\"合計_3日平均\"] = df_pivot[\"合計\"].shift(1).rolling(3).mean()\n",
    "    df_feat[\"合計_3日合計\"] = df_pivot[\"合計\"].shift(1).rolling(3).sum()\n",
    "    df_feat[\"曜日\"] = df_feat.index.dayofweek\n",
    "    df_feat[\"週番号\"] = df_feat.index.isocalendar().week\n",
    "\n",
    "    daily_sum = df_raw.groupby(\"伝票日付\")[\"正味重量\"].sum()\n",
    "    daily_count = df_raw.groupby(\"伝票日付\")[\"受入番号\"].nunique()\n",
    "    daily_avg = daily_sum / daily_count\n",
    "    df_feat[\"1台あたり正味重量_前日中央値\"] = daily_avg.shift(1).expanding().median()\n",
    "\n",
    "    holiday_dates = pd.to_datetime(holidays)\n",
    "    df_feat[\"祝日フラグ\"] = df_feat.index.isin(holiday_dates).astype(int)\n",
    "\n",
    "    df_feat = df_feat.dropna()\n",
    "    df_pivot = df_pivot.loc[df_feat.index]\n",
    "\n",
    "    ab_features = [\n",
    "        \"混合廃棄物A_前日\",\n",
    "        \"混合廃棄物B_前日\",\n",
    "        \"合計_前日\",\n",
    "        \"合計_3日平均\",\n",
    "        \"合計_3日合計\",\n",
    "        \"曜日\",\n",
    "        \"週番号\",\n",
    "        \"1台あたり正味重量_前日中央値\",\n",
    "        \"祝日フラグ\",\n",
    "    ]\n",
    "    target_items = [\"混合廃棄物A\", \"混合廃棄物B\", \"混合廃棄物(ｿﾌｧｰ･家具類)\"]\n",
    "    base_models = [\n",
    "        (\"elastic\", ElasticNet(alpha=0.1, l1_ratio=0.5)),\n",
    "        (\"rf\", RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    ]\n",
    "    meta_model_stage1 = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "    gbdt_model = GradientBoostingRegressor(\n",
    "        n_estimators=150, learning_rate=0.05, max_depth=4, random_state=42\n",
    "    )\n",
    "    kf = KFold(n_splits=5)\n",
    "\n",
    "    # --- ステージ1学習 ---\n",
    "    X_features_all = {}\n",
    "    stacked_preds = {}\n",
    "\n",
    "    for item in target_items:\n",
    "        X = (\n",
    "            df_feat[ab_features]\n",
    "            if item == \"混合廃棄物A\"\n",
    "            else df_feat[[c for c in ab_features if \"1台あたり\" not in c]]\n",
    "        )\n",
    "        y = df_pivot[item]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, shuffle=False\n",
    "        )\n",
    "        X_features_all[item] = X\n",
    "\n",
    "        train_meta = np.zeros((X_train.shape[0], len(base_models)))\n",
    "        for i, (_, model) in enumerate(base_models):\n",
    "            for j, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "                model_ = clone(model)\n",
    "                model_.fit(X_train.iloc[train_idx], y_train.iloc[train_idx])\n",
    "                train_meta[val_idx, i] = model_.predict(X_train.iloc[val_idx])\n",
    "\n",
    "        meta_model_stage1.fit(train_meta, y_train)\n",
    "\n",
    "        test_meta = np.column_stack(\n",
    "            [\n",
    "                clone(model).fit(X_train, y_train).predict(X_test)\n",
    "                for _, model in base_models\n",
    "            ]\n",
    "        )\n",
    "        stacked_preds[item] = meta_model_stage1.predict(test_meta)\n",
    "\n",
    "    index_final = X_test.index\n",
    "    df_stage1 = pd.DataFrame(\n",
    "        {f\"{k}_予測\": v for k, v in stacked_preds.items()}, index=index_final\n",
    "    )\n",
    "    for col in [\n",
    "        \"曜日\",\n",
    "        \"週番号\",\n",
    "        \"合計_前日\",\n",
    "        \"1台あたり正味重量_前日中央値\",\n",
    "        \"祝日フラグ\",\n",
    "    ]:\n",
    "        df_stage1[col] = df_feat.loc[index_final, col]\n",
    "\n",
    "    y_total_final = df_pivot.loc[df_stage1.index, \"合計\"]\n",
    "    gbdt_model.fit(df_stage1, y_total_final)\n",
    "\n",
    "    # --- 分類モデル学習（GBC使用） ---\n",
    "    y_total_binary = (y_total_final < 90000).astype(int)\n",
    "    clf_model = GradientBoostingClassifier(\n",
    "        n_estimators=100, learning_rate=0.05, max_depth=3, random_state=42\n",
    "    )\n",
    "    clf_model.fit(df_stage1.drop(columns=[\"祝日フラグ\"]), y_total_binary)\n",
    "\n",
    "    # --- 評価 ---\n",
    "    r2 = r2_score(y_total_final, gbdt_model.predict(df_stage1))\n",
    "    mae = mean_absolute_error(y_total_final, gbdt_model.predict(df_stage1))\n",
    "\n",
    "    # --- 将来予測 ---\n",
    "    last_date = df_feat.index[-1]\n",
    "    predict_dates = pd.date_range(start=start_date, end=end_date)\n",
    "    residuals = y_total_final - gbdt_model.predict(df_stage1)\n",
    "    bias = residuals.mean()\n",
    "    std = residuals.std()\n",
    "\n",
    "    results = []\n",
    "    for predict_date in predict_dates:\n",
    "        new_row = {\n",
    "            \"混合廃棄物A_前日\": df_pivot.loc[last_date, \"混合廃棄物A\"],\n",
    "            \"混合廃棄物B_前日\": df_pivot.loc[last_date, \"混合廃棄物B\"],\n",
    "            \"合計_前日\": df_pivot.loc[last_date, \"合計\"],\n",
    "            \"合計_3日平均\": df_pivot[\"合計\"].shift(1).rolling(3).mean().loc[last_date],\n",
    "            \"合計_3日合計\": df_pivot[\"合計\"].shift(1).rolling(3).sum().loc[last_date],\n",
    "            \"曜日\": predict_date.dayofweek,\n",
    "            \"週番号\": predict_date.isocalendar().week,\n",
    "            \"1台あたり正味重量_前日中央値\": df_feat[\n",
    "                \"1台あたり正味重量_前日中央値\"\n",
    "            ].iloc[-1],\n",
    "            \"祝日フラグ\": int(predict_date in holiday_dates),\n",
    "        }\n",
    "        df_input = pd.DataFrame(new_row, index=[predict_date])\n",
    "        for item in target_items:\n",
    "            x_item = (\n",
    "                df_input[ab_features]\n",
    "                if item == \"混合廃棄物A\"\n",
    "                else df_input[[c for c in ab_features if \"1台あたり\" not in c]]\n",
    "            )\n",
    "            meta_input = np.column_stack(\n",
    "                [\n",
    "                    clone(model)\n",
    "                    .fit(X_features_all[item], df_pivot.loc[df_feat.index, item])\n",
    "                    .predict(x_item)\n",
    "                    for _, model in base_models\n",
    "                ]\n",
    "            )\n",
    "            df_input[f\"{item}_予測\"] = meta_model_stage1.predict(meta_input)[0]\n",
    "\n",
    "        stage2_input = df_input[\n",
    "            [\n",
    "                f\"{target_items[0]}_予測\",\n",
    "                f\"{target_items[1]}_予測\",\n",
    "                f\"{target_items[2]}_予測\",\n",
    "                \"曜日\",\n",
    "                \"週番号\",\n",
    "                \"合計_前日\",\n",
    "                \"1台あたり正味重量_前日中央値\",\n",
    "                \"祝日フラグ\",\n",
    "            ]\n",
    "        ]\n",
    "        y_pred = gbdt_model.predict(stage2_input)[0]\n",
    "        y_adjusted = y_pred + bias\n",
    "        lower = y_adjusted - 1.96 * std\n",
    "        upper = y_adjusted + 1.96 * std\n",
    "\n",
    "        # --- 分類判定 ---\n",
    "        label = \"通常\"\n",
    "        prob = None\n",
    "        if 85000 <= y_adjusted <= 95000:\n",
    "            X_clf = stage2_input.drop(columns=[\"祝日フラグ\"])\n",
    "            prob = clf_model.predict_proba(X_clf)[0][1]\n",
    "            classification = clf_model.predict(X_clf)[0]\n",
    "            label = \"警告\" if classification == 1 else \"注意\"\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"日付\": predict_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"予測値\": y_pred,\n",
    "                \"補正後予測\": y_adjusted,\n",
    "                \"下限95CI\": lower,\n",
    "                \"上限95CI\": upper,\n",
    "                \"判定ラベル\": label,\n",
    "                \"未満確率\": round(prob, 3) if prob is not None else None,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df_result = pd.DataFrame(results).set_index(\"日付\")\n",
    "    print(f\"✅ R² = {r2:.3f}, MAE = {mae:,.0f} kg\")\n",
    "    return df_result\n",
    "\n",
    "\n",
    "holidays = [\n",
    "    \"2025-01-01\",\n",
    "    \"2025-01-13\",\n",
    "    \"2025-02-11\",\n",
    "    \"2025-02-23\",\n",
    "    \"2025-03-20\",\n",
    "    \"2025-04-29\",\n",
    "    \"2025-05-03\",\n",
    "    \"2025-05-04\",\n",
    "    \"2025-05-05\",\n",
    "    \"2025-05-06\",\n",
    "    \"2025-07-21\",\n",
    "    \"2025-08-11\",\n",
    "    \"2025-09-15\",\n",
    "    \"2025-09-23\",\n",
    "    \"2025-10-13\",\n",
    "    \"2025-11-03\",\n",
    "    \"2025-11-23\",\n",
    "    \"2025-12-23\",\n",
    "]\n",
    "\n",
    "df_raw = pd.read_csv(\"/work/app/data/input/20240501-20250422.csv\")\n",
    "df_pred = train_and_predict_with_holiday(df_raw, \"2024-05-08\", \"2024-05-10\", holidays)\n",
    "df_pred.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b147dfb",
   "metadata": {},
   "source": [
    "### 関数分割\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d90a4ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ R² = 0.997, MAE = 1,379.5486724301336 kg\n",
      "                     予測値         補正後予測        下限95CI        上限95CI 判定ラベル  \\\n",
      "日付                                                                         \n",
      "2025-05-08  90126.643032  90126.643032  86634.010196  93619.275868    注意   \n",
      "2025-05-09  89483.647396  89483.647396  85991.014561  92976.280232    注意   \n",
      "2025-05-10  95706.935769  95706.935769  92214.302933  99199.568605    通常   \n",
      "\n",
      "             未満確率  \n",
      "日付                 \n",
      "2025-05-08  0.092  \n",
      "2025-05-09  0.274  \n",
      "2025-05-10  0.000  \n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# ------------------------- データ前処理 ------------------------- #\n",
    "def preprocess_raw_data(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df_raw.copy()\n",
    "    df[\"伝票日付\"] = df[\"伝票日付\"].str.replace(r\"\\(.*\\)\", \"\", regex=True)\n",
    "    df[\"伝票日付\"] = pd.to_datetime(df[\"伝票日付\"], errors=\"coerce\")\n",
    "    df[\"正味重量\"] = pd.to_numeric(df[\"正味重量\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"正味重量\"])\n",
    "    return df\n",
    "\n",
    "# ------------------------- 特徴量生成 ------------------------- #\n",
    "def create_features(df: pd.DataFrame, holidays: List[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    df_pivot = df.groupby([\"伝票日付\", \"品名\"])[\"正味重量\"].sum().unstack(fill_value=0)\n",
    "    df_pivot[\"合計\"] = df_pivot.sum(axis=1)\n",
    "\n",
    "    df_feat = pd.DataFrame(index=df_pivot.index)\n",
    "    df_feat[\"混合廃棄物A_前日\"] = df_pivot[\"混合廃棄物A\"].shift(1)\n",
    "    df_feat[\"混合廃棄物B_前日\"] = df_pivot[\"混合廃棄物B\"].shift(1)\n",
    "    df_feat[\"合計_前日\"] = df_pivot[\"合計\"].shift(1)\n",
    "    df_feat[\"合計_3日平均\"] = df_pivot[\"合計\"].shift(1).rolling(3).mean()\n",
    "    df_feat[\"合計_3日合計\"] = df_pivot[\"合計\"].shift(1).rolling(3).sum()\n",
    "    df_feat[\"曜日\"] = df_feat.index.dayofweek\n",
    "    df_feat[\"週番号\"] = df_feat.index.isocalendar().week\n",
    "\n",
    "    daily_sum = df.groupby(\"伝票日付\")[\"正味重量\"].sum()\n",
    "    daily_count = df.groupby(\"伝票日付\")[\"受入番号\"].nunique()\n",
    "    daily_avg = daily_sum / daily_count\n",
    "    df_feat[\"1台あたり正味重量_前日中央値\"] = daily_avg.shift(1).expanding().median()\n",
    "\n",
    "    holiday_dates = pd.to_datetime(holidays)\n",
    "    df_feat[\"祝日フラグ\"] = df_feat.index.isin(holiday_dates).astype(int)\n",
    "\n",
    "    df_feat = df_feat.dropna()\n",
    "    df_pivot = df_pivot.loc[df_feat.index]\n",
    "    return df_feat, df_pivot\n",
    "\n",
    "# ------------------------- モデル構築 ------------------------- #\n",
    "def train_stack_models(\n",
    "    df_feat: pd.DataFrame,\n",
    "    df_pivot: pd.DataFrame,\n",
    "    ab_features: List[str],\n",
    "    target_items: List[str],\n",
    "    base_models: List[Tuple[str, object]],\n",
    "    meta_model_stage1,\n",
    "    kf\n",
    ") -> Tuple[dict, dict]:\n",
    "    X_features_all = {}\n",
    "    stacked_preds = {}\n",
    "\n",
    "    for item in target_items:\n",
    "        X = (\n",
    "            df_feat[ab_features]\n",
    "            if item == \"混合廃棄物A\"\n",
    "            else df_feat[[c for c in ab_features if \"1台あたり\" not in c]]\n",
    "        )\n",
    "        y = df_pivot[item]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "        X_features_all[item] = X\n",
    "\n",
    "        train_meta = np.zeros((X_train.shape[0], len(base_models)))\n",
    "        for i, (_, model) in enumerate(base_models):\n",
    "            for train_idx, val_idx in kf.split(X_train):\n",
    "                model_ = clone(model)\n",
    "                model_.fit(X_train.iloc[train_idx], y_train.iloc[train_idx])\n",
    "                train_meta[val_idx, i] = model_.predict(X_train.iloc[val_idx])\n",
    "\n",
    "        meta_model_stage1.fit(train_meta, y_train)\n",
    "\n",
    "        test_meta = np.column_stack([\n",
    "            clone(model).fit(X_train, y_train).predict(X_test) for _, model in base_models\n",
    "        ])\n",
    "        stacked_preds[item] = meta_model_stage1.predict(test_meta)\n",
    "\n",
    "    return X_features_all, stacked_preds\n",
    "\n",
    "# ------------------------- メイン統合関数 ------------------------- #\n",
    "def train_and_predict_with_holiday(df_raw: pd.DataFrame, start_date: str, end_date: str, holidays: List[str]) -> pd.DataFrame:\n",
    "    df_clean = preprocess_raw_data(df_raw)\n",
    "    df_feat, df_pivot = create_features(df_clean, holidays)\n",
    "\n",
    "    ab_features = [\n",
    "        \"混合廃棄物A_前日\", \"混合廃棄物B_前日\", \"合計_前日\", \"合計_3日平均\", \"合計_3日合計\",\n",
    "        \"曜日\", \"週番号\", \"1台あたり正味重量_前日中央値\", \"祝日フラグ\"\n",
    "    ]\n",
    "    target_items = [\"混合廃棄物A\", \"混合廃棄物B\", \"混合廃棄物(ｿﾌｧｰ･家具類)\"]\n",
    "    base_models = [\n",
    "        (\"elastic\", ElasticNet(alpha=0.1, l1_ratio=0.5)),\n",
    "        (\"rf\", RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    ]\n",
    "    meta_model_stage1 = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "    gbdt_model = GradientBoostingRegressor(n_estimators=150, learning_rate=0.05, max_depth=4, random_state=42)\n",
    "    kf = KFold(n_splits=5)\n",
    "\n",
    "    X_features_all, stacked_preds = train_stack_models(df_feat, df_pivot, ab_features, target_items, base_models, meta_model_stage1, kf)\n",
    "\n",
    "    index_final = df_feat.iloc[-len(list(stacked_preds.values())[0]):].index\n",
    "    df_stage1 = pd.DataFrame({f\"{k}_予測\": v for k, v in stacked_preds.items()}, index=index_final)\n",
    "    for col in [\"曜日\", \"週番号\", \"合計_前日\", \"1台あたり正味重量_前日中央値\", \"祝日フラグ\"]:\n",
    "        df_stage1[col] = df_feat.loc[index_final, col]\n",
    "\n",
    "    y_total_final = df_pivot.loc[index_final, \"合計\"]\n",
    "    gbdt_model.fit(df_stage1, y_total_final)\n",
    "\n",
    "    y_total_binary = (y_total_final < 90000).astype(int)\n",
    "    clf_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "    clf_model.fit(df_stage1.drop(columns=[\"祝日フラグ\"]), y_total_binary)\n",
    "\n",
    "    # --- 将来予測出力 --- #\n",
    "    residuals = y_total_final - gbdt_model.predict(df_stage1)\n",
    "    bias = residuals.mean()\n",
    "    std = residuals.std()\n",
    "\n",
    "    holiday_dates = pd.to_datetime(holidays)\n",
    "    predict_dates = pd.date_range(start=start_date, end=end_date)\n",
    "    last_date = df_feat.index[-1]\n",
    "\n",
    "    results = []\n",
    "    for predict_date in predict_dates:\n",
    "        new_row = {\n",
    "            \"混合廃棄物A_前日\": df_pivot.loc[last_date, \"混合廃棄物A\"],\n",
    "            \"混合廃棄物B_前日\": df_pivot.loc[last_date, \"混合廃棄物B\"],\n",
    "            \"合計_前日\": df_pivot.loc[last_date, \"合計\"],\n",
    "            \"合計_3日平均\": df_pivot[\"合計\"].shift(1).rolling(3).mean().loc[last_date],\n",
    "            \"合計_3日合計\": df_pivot[\"合計\"].shift(1).rolling(3).sum().loc[last_date],\n",
    "            \"曜日\": predict_date.dayofweek,\n",
    "            \"週番号\": predict_date.isocalendar().week,\n",
    "            \"1台あたり正味重量_前日中央値\": df_feat[\"1台あたり正味重量_前日中央値\"].iloc[-1],\n",
    "            \"祝日フラグ\": int(predict_date in holiday_dates),\n",
    "        }\n",
    "        df_input = pd.DataFrame(new_row, index=[predict_date])\n",
    "\n",
    "        for item in target_items:\n",
    "            x_item = (\n",
    "                df_input[ab_features]\n",
    "                if item == \"混合廃棄物A\"\n",
    "                else df_input[[c for c in ab_features if \"1台あたり\" not in c]]\n",
    "            )\n",
    "            meta_input = np.column_stack([\n",
    "                clone(model).fit(X_features_all[item], df_pivot.loc[df_feat.index, item]).predict(x_item)\n",
    "                for _, model in base_models\n",
    "            ])\n",
    "            df_input[f\"{item}_予測\"] = meta_model_stage1.predict(meta_input)[0]\n",
    "\n",
    "        stage2_input = df_input[[\n",
    "            f\"{target_items[0]}_予測\",\n",
    "            f\"{target_items[1]}_予測\",\n",
    "            f\"{target_items[2]}_予測\",\n",
    "            \"曜日\", \"週番号\", \"合計_前日\", \"1台あたり正味重量_前日中央値\", \"祝日フラグ\"\n",
    "        ]]\n",
    "        y_pred = gbdt_model.predict(stage2_input)[0]\n",
    "        y_adjusted = y_pred + bias\n",
    "        lower = y_adjusted - 1.96 * std\n",
    "        upper = y_adjusted + 1.96 * std\n",
    "\n",
    "        label = \"通常\"\n",
    "        prob = None\n",
    "        if 85000 <= y_adjusted <= 95000:\n",
    "            X_clf = stage2_input.drop(columns=[\"祝日フラグ\"])\n",
    "            prob = clf_model.predict_proba(X_clf)[0][1]\n",
    "            classification = clf_model.predict(X_clf)[0]\n",
    "            label = \"警告\" if classification == 1 else \"注意\"\n",
    "\n",
    "        results.append({\n",
    "            \"日付\": predict_date.strftime(\"%Y-%m-%d\"),\n",
    "            \"予測値\": y_pred,\n",
    "            \"補正後予測\": y_adjusted,\n",
    "            \"下限95CI\": lower,\n",
    "            \"上限95CI\": upper,\n",
    "            \"判定ラベル\": label,\n",
    "            \"未満確率\": round(prob, 3) if prob is not None else None,\n",
    "        })\n",
    "\n",
    "    df_result = pd.DataFrame(results).set_index(\"日付\")\n",
    "    print(f\"✅ R² = {r2_score(y_total_final, gbdt_model.predict(df_stage1)):.3f}, MAE = {mean_absolute_error(y_total_final, gbdt_model.predict(df_stage1)):,} kg\")\n",
    "    return df_result\n",
    "\n",
    "# ------------------------- 呼び出し例 ------------------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    holidays = [\n",
    "        \"2025-01-01\", \"2025-01-13\", \"2025-02-11\", \"2025-02-23\",\n",
    "        \"2025-03-20\", \"2025-04-29\", \"2025-05-03\", \"2025-05-04\",\n",
    "        \"2025-05-05\", \"2025-05-06\", \"2025-07-21\", \"2025-08-11\",\n",
    "        \"2025-09-15\", \"2025-09-23\", \"2025-10-13\", \"2025-11-03\",\n",
    "        \"2025-11-23\", \"2025-12-23\"\n",
    "    ]\n",
    "    df_raw = pd.read_csv(\"/work/app/data/input/20240501-20250422.csv\")\n",
    "    df_result = train_and_predict_with_holiday(df_raw, \"2025-05-08\", \"2025-05-10\", holidays)\n",
    "    print(df_result.fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560e4033",
   "metadata": {},
   "source": [
    "# セーブとロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eacadbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. モデルを作成し、保存するスクリプト（train_and_save.py）\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from your_module import (\n",
    "    preprocess_raw_data,\n",
    "    create_features,\n",
    "    train_stack_models,\n",
    "    save_models\n",
    ")\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# --- 引数で保存先モデルディレクトリ指定 ---\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_dir\", type=str, default=\"models\", help=\"保存するモデルのディレクトリ\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# --- ハイパーパラメータと共通設定 ---\n",
    "ab_features = [\n",
    "    \"混合廃棄物A_前日\", \"混合廃棄物B_前日\", \"合計_前日\", \"合計_3日平均\", \"合計_3日合計\",\n",
    "    \"曜日\", \"週番号\", \"1台あたり正味重量_前日中央値\", \"祝日フラグ\"\n",
    "]\n",
    "target_items = [\"混合廃棄物A\", \"混合廃棄物B\", \"混合廃棄物(ｿﾌｧｰ･家具類)\"]\n",
    "base_models = [\n",
    "    (\"elastic\", ElasticNet(alpha=0.1, l1_ratio=0.5)),\n",
    "    (\"rf\", RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "]\n",
    "meta_model_stage1 = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "gbdt_model = GradientBoostingRegressor(n_estimators=150, learning_rate=0.05, max_depth=4, random_state=42)\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# --- データ読み込みと前処理 ---\n",
    "holidays = [...]  # 祝日リストを指定\n",
    "df_raw = pd.read_csv(\"/path/to/your/data.csv\")\n",
    "df_clean = preprocess_raw_data(df_raw)\n",
    "df_feat, df_pivot = create_features(df_clean, holidays)\n",
    "\n",
    "# --- スタッキング学習 ---\n",
    "X_features_all, stacked_preds = train_stack_models(\n",
    "    df_feat, df_pivot, ab_features, target_items,\n",
    "    base_models, meta_model_stage1, kf\n",
    ")\n",
    "\n",
    "index_final = df_feat.iloc[-len(list(stacked_preds.values())[0]):].index\n",
    "df_stage1 = pd.DataFrame({f\"{k}_予測\": v for k, v in stacked_preds.items()}, index=index_final)\n",
    "for col in [\"曜日\", \"週番号\", \"合計_前日\", \"1台あたり正味重量_前日中央値\", \"祝日フラグ\"]:\n",
    "    df_stage1[col] = df_feat.loc[index_final, col]\n",
    "\n",
    "y_total_final = df_pivot.loc[index_final, \"合計\"]\n",
    "gbdt_model.fit(df_stage1, y_total_final)\n",
    "\n",
    "clf_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "y_total_binary = (y_total_final < 90000).astype(int)\n",
    "clf_model.fit(df_stage1.drop(columns=[\"祝日フラグ\"]), y_total_binary)\n",
    "\n",
    "residuals = y_total_final - gbdt_model.predict(df_stage1)\n",
    "bias = residuals.mean()\n",
    "std = residuals.std()\n",
    "\n",
    "save_models(gbdt_model, meta_model_stage1, clf_model, X_features_all, bias, std, output_dir=args.model_dir)\n",
    "print(f\"✅ モデル保存完了（保存先: {args.model_dir}）\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1669d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(\n",
    "    df_raw: pd.DataFrame,\n",
    "    holidays: list[str],\n",
    "    model_dir: str = \"models\"\n",
    "):\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "    from sklearn.model_selection import KFold\n",
    "\n",
    "    df_clean = preprocess_raw_data(df_raw)\n",
    "    df_feat, df_pivot = create_features(df_clean, holidays)\n",
    "\n",
    "    ab_features = [\n",
    "        \"混合廃棄物A_前日\", \"混合廃棄物B_前日\", \"合計_前日\", \"合計_3日平均\", \"合計_3日合計\",\n",
    "        \"曜日\", \"週番号\", \"1台あたり正味重量_前日中央値\", \"祝日フラグ\"\n",
    "    ]\n",
    "    target_items = [\"混合廃棄物A\", \"混合廃棄物B\", \"混合廃棄物(ｿﾌｧｰ･家具類)\"]\n",
    "    base_models = [\n",
    "        (\"elastic\", ElasticNet(alpha=0.1, l1_ratio=0.5)),\n",
    "        (\"rf\", RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    ]\n",
    "    meta_model_stage1 = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "    gbdt_model = GradientBoostingRegressor(n_estimators=150, learning_rate=0.05, max_depth=4, random_state=42)\n",
    "    kf = KFold(n_splits=5)\n",
    "\n",
    "    X_features_all, stacked_preds = train_stack_models(\n",
    "        df_feat, df_pivot, ab_features, target_items, base_models, meta_model_stage1, kf\n",
    "    )\n",
    "\n",
    "    index_final = df_feat.iloc[-len(list(stacked_preds.values())[0]):].index\n",
    "    df_stage1 = pd.DataFrame({f\"{k}_予測\": v for k, v in stacked_preds.items()}, index=index_final)\n",
    "    for col in [\"曜日\", \"週番号\", \"合計_前日\", \"1台あたり正味重量_前日中央値\", \"祝日フラグ\"]:\n",
    "        df_stage1[col] = df_feat.loc[index_final, col]\n",
    "\n",
    "    y_total_final = df_pivot.loc[index_final, \"合計\"]\n",
    "    gbdt_model.fit(df_stage1, y_total_final)\n",
    "\n",
    "    y_total_binary = (y_total_final < 90000).astype(int)\n",
    "    clf_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "    clf_model.fit(df_stage1.drop(columns=[\"祝日フラグ\"]), y_total_binary)\n",
    "\n",
    "    residuals = y_total_final - gbdt_model.predict(df_stage1)\n",
    "    bias = residuals.mean()\n",
    "    std = residuals.std()\n",
    "\n",
    "    save_models(gbdt_model, meta_model_stage1, clf_model, X_features_all, bias, std, output_dir=model_dir)\n",
    "\n",
    "    print(f\"✅ モデル保存完了（保存先: {model_dir}）\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "554c0b58",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"Ellipsis\" doesn't match format \"%Y-%m-%d\", at position 2. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m df_raw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/work/app/data/input/20240501-20250422.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m holidays \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2025-01-01\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2025-01-13\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain_and_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholidays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/work/app/data/models\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 11\u001b[0m, in \u001b[0;36mtrain_and_save_model\u001b[0;34m(df_raw, holidays, model_dir)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KFold\n\u001b[1;32m     10\u001b[0m df_clean \u001b[38;5;241m=\u001b[39m preprocess_raw_data(df_raw)\n\u001b[0;32m---> 11\u001b[0m df_feat, df_pivot \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholidays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m ab_features \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m混合廃棄物A_前日\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m混合廃棄物B_前日\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m合計_前日\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m合計_3日平均\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m合計_3日合計\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m曜日\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m週番号\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1台あたり正味重量_前日中央値\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m祝日フラグ\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m ]\n\u001b[1;32m     17\u001b[0m target_items \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m混合廃棄物A\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m混合廃棄物B\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m混合廃棄物(ｿﾌｧｰ･家具類)\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[26], line 38\u001b[0m, in \u001b[0;36mcreate_features\u001b[0;34m(df, holidays)\u001b[0m\n\u001b[1;32m     35\u001b[0m daily_avg \u001b[38;5;241m=\u001b[39m daily_sum \u001b[38;5;241m/\u001b[39m daily_count\n\u001b[1;32m     36\u001b[0m df_feat[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1台あたり正味重量_前日中央値\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m daily_avg\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpanding()\u001b[38;5;241m.\u001b[39mmedian()\n\u001b[0;32m---> 38\u001b[0m holiday_dates \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mholidays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m df_feat[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m祝日フラグ\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_feat\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39misin(holiday_dates)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     41\u001b[0m df_feat \u001b[38;5;241m=\u001b[39m df_feat\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:1099\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         result \u001b[38;5;241m=\u001b[39m _convert_and_box_cache(argc, cache_array)\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43margc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m     result \u001b[38;5;241m=\u001b[39m convert_listlike(np\u001b[38;5;241m.\u001b[39marray([arg]), \u001b[38;5;28mformat\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    457\u001b[0m     arg,\n\u001b[1;32m    458\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data \"Ellipsis\" doesn't match format \"%Y-%m-%d\", at position 2. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# from your_module import train_and_save_model\n",
    "\n",
    "df_raw = pd.read_csv(\"/work/app/data/input/20240501-20250422.csv\")\n",
    "holidays = [\"2025-01-01\", \"2025-01-13\", ...]\n",
    "train_and_save_model(df_raw, holidays, model_dir=\"/work/app/data/models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19040c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
