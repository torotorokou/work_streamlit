# --- ãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿ ---
import streamlit as st
import os
import json
from dotenv import load_dotenv
from openai import OpenAI
from pdf2image import convert_from_path
from PIL import Image
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings  # ä¿®æ­£: langchain_openaiã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ


def load_config():
    """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚

    OPENAI_API_KEY ãŒç’°å¢ƒå¤‰æ•°ã«è¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã€OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ None ã‚’è¿”ã—ã¾ã™ã€‚

    æˆ»ã‚Šå€¤:
        tuple: OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆã¾ãŸã¯ Noneï¼‰ã€PDFãƒ‘ã‚¹ã€JSONãƒ‘ã‚¹ã€FAISSãƒ‘ã‚¹ã€OpenAI APIã‚­ãƒ¼ã‚’å«ã‚€ã‚¿ãƒ—ãƒ«ã€‚
    """

    load_dotenv()
    openai_api_key = os.getenv("OPENAI_API_KEY")
    # OpenAI APIã‚­ãƒ¼ã®å–å¾—
    if not openai_api_key or len(openai_api_key) < 32 or not openai_api_key.isalnum():
        st.warning(
            "OPENAI_API_KEY ãŒç’°å¢ƒå¤‰æ•°ã«è¨­å®šã•ã‚Œã¦ã„ãªã„ã‹ã€ç„¡åŠ¹ã§ã™ã€‚APIã‚­ãƒ¼ã‚’æ­£ã—ãè¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )
        st.warning(
            "OPENAI_API_KEY ãŒç’°å¢ƒå¤‰æ•°ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )
        client = None
    else:
        client = OpenAI(api_key=openai_api_key)

    # ãƒ‘ã‚¹ã®å–å¾—
    PDF_PATH = "data/SOLVEST.pdf"
    JSON_PATH = "structured_SOLVEST_output_final.json"
    FAISS_PATH = "vectorstore/solvest_faiss_corrected"

    return client, PDF_PATH, JSON_PATH, FAISS_PATH, openai_api_key


def render_education_gpt_page():
    # ã“ã“ã«ä»Šã® Streamlit UI éƒ¨åˆ†ã‚’ã™ã¹ã¦å…¥ã‚Œã‚‹
    # st.title("ğŸ“˜ æ•™è‚²GPTã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
    st.markdown(
        "SOLVESTã«ã¤ã„ã¦è³ªå•ã§ãã¾ã™ã€‚ã¾ãšæœ€åˆã«çŸ¥ã‚ŠãŸã„ã“ã¨ã‚’ä¸€è¨€ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
    )
    # --- è¨­å®šã®èª­ã¿è¾¼ã¿ ---
    client, PDF_PATH, JSON_PATH, FAISS_PATH, openai_api_key = load_config()

    # --- åˆæœŸè¨­å®š ---

    # --- PDFç”»åƒã®èª­ã¿è¾¼ã¿ ---
    @st.cache_resource
    def load_pdf_first_page(path, dpi=100):
        # PDFã®1ãƒšãƒ¼ã‚¸ç›®ã‚’ç”»åƒã¨ã—ã¦èª­ã¿è¾¼ã‚€
        return convert_from_path(path, dpi=dpi, first_page=1, last_page=1)

    @st.cache_resource
    def load_pdf_page(path, page_number, dpi=100):
        # æŒ‡å®šãƒšãƒ¼ã‚¸ã®PDFã‚’ç”»åƒã¨ã—ã¦èª­ã¿è¾¼ã‚€
        return convert_from_path(
            path, dpi=dpi, first_page=page_number, last_page=page_number
        )[0]

    # --- ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢èª­ã¿è¾¼ã¿ ---
    @st.cache_resource
    def load_vectorstore():
        # FAISSãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®ãƒ­ãƒ¼ãƒ‰
        if not openai_api_key:
            st.warning(
                "OPENAI_API_KEY ãŒæœªè¨­å®šã®ãŸã‚ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã€‚"
            )
            return None
        embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        return FAISS.load_local(
            FAISS_PATH, embeddings=embeddings, allow_dangerous_deserialization=True
        )

    vectorstore = load_vectorstore()

    # --- JSONã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªãƒ»ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªã‚’å–å¾— ---
    @st.cache_data
    def load_json_data(json_path):
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è¿”ã™
        with open(json_path, encoding="utf-8") as f:
            data = json.load(f)
        return data

    json_data = load_json_data(JSON_PATH)

    @st.cache_data
    def extract_categories_and_titles(data):
        # JSONã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã¨ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªã‚’æŠ½å‡º
        categories = set()
        subcategories = {}
        for section in data:
            cats = section.get("category", [])
            if isinstance(cats, str):
                cats = [cats]
            for cat in cats:
                categories.add(cat)
                subcategories.setdefault(cat, set()).add(section.get("title"))
        categories = sorted(categories)
        for k in subcategories:
            subcategories[k] = sorted(subcategories[k])
        return categories, subcategories

    categories, subcategory_map = extract_categories_and_titles(json_data)

    # --- ã‚«ãƒ†ã‚´ãƒªåˆ¥ è³ªå•ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ ---
    category_question_templates = {
        # å„ã‚«ãƒ†ã‚´ãƒªã«å¯¾ã—ã¦è³ªå•ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”¨æ„
        "å‡¦ç†å·¥ç¨‹": [
            "ã“ã®å·¥ç¨‹ã®æµã‚Œã‚’æ•™ãˆã¦",
            "å‡¦ç†å¯¾è±¡ã®å»ƒæ£„ç‰©ã¯ï¼Ÿ",
            "ä½¿ã‚ã‚Œã¦ã„ã‚‹è¨­å‚™ã¯ï¼Ÿ",
            "å®‰å…¨å¯¾ç­–ã‚„æ³¨æ„ç‚¹ã¯ï¼Ÿ",
            "å‡¦ç†èƒ½åŠ›ã¯ï¼Ÿ",
        ],
        "è¨­å‚™": [
            "ã“ã®è¨­å‚™ã®ç”¨é€”ã¯ï¼Ÿ",
            "ã“ã®è¨­å‚™ã®å‡¦ç†èƒ½åŠ›ã¯ï¼Ÿ",
            "è¨­å‚™ã®ä»•æ§˜ã¨ç‰¹å¾´ã¯ï¼Ÿ",
            "å®‰å…¨å¯¾ç­–ã‚„æ³¨æ„ç‚¹ã¯ï¼Ÿ",
            "ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹é »åº¦ã¯ï¼Ÿ",
        ],
        "è¡Œæ”¿ãƒ»è¨±èªå¯": [
            "ã“ã®æ–½è¨­ã«å¿…è¦ãªè¨±å¯ã¯ï¼Ÿ",
            "è¨±èªå¯ã®ç”³è«‹æ‰‹ç¶šãã¯ï¼Ÿ",
            "è¡Œæ”¿æå‡ºæ›¸é¡ã«ä½•ãŒå¿…è¦ï¼Ÿ",
            "è¨±èªå¯å–å¾—ã®æµã‚Œã¯ï¼Ÿ",
            "è¨±å¯ã®æ›´æ–°ã‚„ç®¡ç†ã¯ï¼Ÿ",
        ],
        "ç”£å»ƒåˆ†é¡ãƒ»å“ç›®": [
            "ã“ã®å“ç›®ã¯ã©ã‚“ãªå»ƒæ£„ç‰©ï¼Ÿ",
            "ã“ã®å“ç›®ã®å‡¦ç†æ–¹æ³•ã¯ï¼Ÿ",
            "æ¬å…¥æ™‚ã®æ³¨æ„ç‚¹ã¯ï¼Ÿ",
            "å‡¦ç†å¾Œã®æ¬å‡ºå…ˆã¯ï¼Ÿ",
            "é–¢é€£ã™ã‚‹è¨­å‚™ã¯ï¼Ÿ",
        ],
        "æ–½è¨­": [
            "æ–½è¨­ã®ç¶­æŒç®¡ç†é …ç›®ã¯ï¼Ÿ",
            "ç‚¹æ¤œé »åº¦ã‚„ç®¡ç†æ–¹æ³•ã¯ï¼Ÿ",
            "è¨­å‚™ã”ã¨ã®ç®¡ç†å†…å®¹ã¯ï¼Ÿ",
            "ç®¡ç†è¨˜éŒ²ã¯ã©ã®ã‚ˆã†ã«ã™ã‚‹ï¼Ÿ",
            "ç•°å¸¸æ™‚ã®å¯¾å¿œã¯ï¼Ÿ",
        ],
        "default": [
            "ã“ã®å·¥ç¨‹ã®æµã‚Œã‚’æ•™ãˆã¦",
            "å‡¦ç†å¯¾è±¡ã®å»ƒæ£„ç‰©ã¯ï¼Ÿ",
            "ä½¿ã‚ã‚Œã¦ã„ã‚‹è¨­å‚™ã¯ï¼Ÿ",
            "å‡¦ç†èƒ½åŠ›ã¯ï¼Ÿ",
            "å®‰å…¨å¯¾ç­–ã‚„æ³¨æ„ç‚¹ã¯ï¼Ÿ",
        ],
    }

    # --- ã‚«ãƒ†ã‚´ãƒªsuggestionç”¨é–¢æ•° ---
    def suggest_category(query_input: str) -> str:
        # GPTã‚’ä½¿ã£ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‹ã‚‰æœ€é©ãªã‚«ãƒ†ã‚´ãƒªã‚’ææ¡ˆã™ã‚‹
        prompt = f"""
    ä»¥ä¸‹ã¯ã€æ—¥æœ¬ã®ç”£æ¥­å»ƒæ£„ç‰©å‡¦ç†ã«é–¢ã™ã‚‹æ•™è‚²ç”¨AIã‚·ã‚¹ãƒ†ãƒ ã§ä½¿ã‚ã‚Œã‚‹ã‚«ãƒ†ã‚´ãƒªã®ä¸€è¦§ã§ã™ï¼š
    
    - å‡¦ç†å·¥ç¨‹
    - è¨­å‚™
    - è¡Œæ”¿ãƒ»è¨±èªå¯
    - ç”£å»ƒåˆ†é¡ãƒ»å“ç›®
    - æ–½è¨­
    
    æ¬¡ã®è³ªå•ã¯ã€ã©ã®ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡ã™ã‚‹ã®ãŒã‚‚ã£ã¨ã‚‚é©åˆ‡ã§ã—ã‚‡ã†ã‹ï¼Ÿ
    ã‚«ãƒ†ã‚´ãƒªåã‚’1ã¤ã ã‘å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ï¼ˆãã‚Œä»¥å¤–ã¯å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ï¼‰
    
    ã€è³ªå•ã€‘  
    {query_input}
    """
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": "ã‚ãªãŸã¯æ—¥æœ¬ã®ç”£æ¥­å»ƒæ£„ç‰©å‡¦ç†ã®ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã«è©³ã—ã„å°‚é–€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
                },
                {"role": "user", "content": prompt},
            ],
        )
        suggestion = response.choices[0].message.content.strip()
        return suggestion

    # --- UIæ§‹ç¯‰ ---
    # --- ã‚¿ã‚¤ãƒˆãƒ«ãƒ»èª¬æ˜ ---
    st.title("ğŸ“˜ æ•™è‚²GPTã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
    st.markdown(
        "SOLVESTã«ã¤ã„ã¦è³ªå•ã§ãã¾ã™ã€‚ã¾ãšæœ€åˆã«çŸ¥ã‚ŠãŸã„ã“ã¨ã‚’ä¸€è¨€ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
    )

    # --- PDF 1ãƒšãƒ¼ã‚¸ç›® ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ---
    with st.expander("ğŸ“„ PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ1ãƒšãƒ¼ã‚¸ç›®ã®ã¿å…ˆã«è¡¨ç¤ºï¼‰"):
        pdf_first_page = load_pdf_first_page(PDF_PATH)
        st.image(pdf_first_page[0], caption="Page 1", use_column_width=True)

    # --- ã‚¹ãƒ†ãƒƒãƒ—â‘  ãƒ¦ãƒ¼ã‚¶ãƒ¼è‡ªç”±å…¥åŠ› ---
    query_input = st.text_input(
        "çŸ¥ã‚ŠãŸã„ã“ã¨ï¼ˆä¾‹ï¼šå…­é¢æ¢±åŒ…æ©Ÿã®å‡¦ç†èƒ½åŠ›ã€è¨±èªå¯ã®å–å¾—æ–¹æ³• ãªã©ï¼‰"
    )

    # --- ã‚¹ãƒ†ãƒƒãƒ—â‘¡ ã‚«ãƒ†ã‚´ãƒªè‡ªå‹•ææ¡ˆ ---
    suggested_category = None
    if st.button("â¡ï¸ ã‚«ãƒ†ã‚´ãƒªã‚’è‡ªå‹•ææ¡ˆ"):
        if query_input.strip():
            with st.spinner("ğŸ¤– ã‚«ãƒ†ã‚´ãƒªã‚’ææ¡ˆä¸­..."):
                suggested_category = suggest_category(query_input)
                st.session_state.suggested_category = suggested_category
        else:
            st.warning("ã¾ãšçŸ¥ã‚ŠãŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    # --- ã‚¹ãƒ†ãƒƒãƒ—â‘¢ ã‚«ãƒ†ã‚´ãƒªé¸æŠbox ---
    default_category = st.session_state.get("suggested_category", None)
    main_category = st.selectbox(
        "ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ",
        options=categories,
        index=(
            categories.index(default_category) if default_category in categories else 0
        ),
    )

    # --- ã‚¹ãƒ†ãƒƒãƒ—â‘£ å¯¾è±¡é¸æŠ ---
    category_template = category_question_templates.get(
        main_category, category_question_templates["default"]
    )
    subcategory_options = (
        ["è‡ªç”±å…¥åŠ›"] + subcategory_map.get(main_category, []) + category_template
    )
    sub_category = st.selectbox("å¯¾è±¡ã‚’é¸æŠ", options=subcategory_options)

    # --- è³ªå•æ–‡æ§‹ç¯‰ ---
    if sub_category == "è‡ªç”±å…¥åŠ›":
        user_input = st.text_area("ã•ã‚‰ã«è©³ã—ãè³ªå•ã‚’å…¥åŠ›", height=100)
        query = user_input if user_input.strip() else query_input
    else:
        query = (
            f"{query_input} ã«é–¢ã—ã¦ã€{sub_category} ã‚’è©³ã—ãæ•™ãˆã¦ãã ã•ã„ã€‚"
            if query_input.strip()
            else f"{sub_category} ã«é–¢ã—ã¦ã€è©³ã—ãæ•™ãˆã¦ãã ã•ã„ã€‚"
        )

    # --- å›ç­”ç”Ÿæˆ ---
    def generate_answer(query: str, selected_category: str):
        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢æ¤œç´¢ã§é–¢é€£æ–‡æ›¸å–å¾—
        docs = vectorstore.max_marginal_relevance_search(query, k=5, fetch_k=30)

        # é¸æŠã‚«ãƒ†ã‚´ãƒªãŒã‚ã‚‹å ´åˆã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if selected_category:
            docs = [
                doc
                for doc in docs
                if selected_category in doc.metadata.get("category", [])
            ]

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
        context = "\n".join([doc.page_content for doc in docs])
        sources = [
            (doc.metadata.get("source", "ä¸æ˜"), doc.metadata.get("page", "ä¸æ˜"))
            for doc in docs
        ]

        # å›ç­”ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        prompt = f"""
    ä»¥ä¸‹ã¯ã€ç”£æ¥­å»ƒæ£„ç‰©ã®å‡¦ç†ãƒ»è¨­å‚™ãƒ»å·¥ç¨‹ã«é–¢ã™ã‚‹æ§‹é€ åŒ–æŠ€è¡“æ–‡æ›¸ã®æŠœç²‹ã§ã™ã€‚
    ã“ã®æŠœç²‹ã«åŸºã¥ãã€ä»¥ä¸‹ã®è³ªå•ã«å¯¾ã—ã¦ **ã§ãã‚‹é™ã‚Šæ–‡æ›¸å†…å®¹ã‚’å„ªå…ˆã—ãªãŒã‚‰ã€å·¥ç¨‹é †ãƒ»è«–ç†é †ã«æ²¿ã£ã¦æ­£ç¢ºã‹ã¤å®Ÿå‹™çš„ã«**ç­”ãˆã¦ãã ã•ã„ã€‚
    
    ã€è³‡æ–™æŠœç²‹ã€‘
    {context}
    
    ã€è³ªå•ã€‘
    {query}
    
    ### ã€å›ç­”ãƒ«ãƒ¼ãƒ«ã€‘
    1. è³‡æ–™ã®è¨˜è¼‰ã«åŸºã¥ã„ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚
    2. æ˜è¨˜ãŒãªã„å ´åˆã¯ä¸€èˆ¬çš„è¦‹è§£ã§è£œè¶³ã—ã¦ãã ã•ã„ã€‚
    3. å›ç­”ã¯ 1. 2. 3. ã®ã‚ˆã†ã«ç®‡æ¡æ›¸ãã§ã€‚
    4. ä¿¡é ¼åº¦ã‚„å‡ºå…¸ï¼ˆãƒšãƒ¼ã‚¸ç•ªå·ï¼‰ã‚‚å¯èƒ½ãªé™ã‚Šæ˜ç¤ºã—ã¦ãã ã•ã„ã€‚
    """
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": "ã‚ãªãŸã¯æ—¥æœ¬ã®ç”£æ¥­å»ƒæ£„ç‰©å‡¦ç†æ–‡æ›¸ã‚’ã‚‚ã¨ã«å›ç­”ã™ã‚‹å°‚é–€AIã§ã™ã€‚",
                },
                {"role": "user", "content": prompt},
            ],
        )
        return response.choices[0].message.content, sources

    # --- å›ç­”è¡¨ç¤º ---
    if st.button("â¡ï¸ é€ä¿¡") and query.strip():
        with st.spinner("ğŸ¤– å›ç­”ç”Ÿæˆä¸­..."):
            answer, sources = generate_answer(query, main_category)
            st.session_state.last_response = answer
            st.session_state.sources = sources

    if "last_response" in st.session_state:
        st.success("âœ… å›ç­”")
        st.markdown(st.session_state.last_response)

        if "sources" in st.session_state:
            # PDFãƒšãƒ¼ã‚¸ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®åˆæœŸåŒ–
            if "cache_pdf_pages" not in st.session_state:
                st.session_state.cache_pdf_pages = {}

            # å‡ºå…¸ãƒšãƒ¼ã‚¸ç•ªå·ã®æŠ½å‡º
            pages = set(int(p) for _, p in st.session_state.sources if str(p).isdigit())
            st.markdown("ğŸ“„ **å‡ºå…¸ãƒšãƒ¼ã‚¸:** " + ", ".join([f"Page {p}" for p in pages]))

            # å‡ºå…¸ãƒšãƒ¼ã‚¸ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
            with st.expander("ğŸ“˜ å‡ºå…¸ãƒšãƒ¼ã‚¸ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                for p in sorted(pages):
                    if isinstance(p, int) and p >= 1:
                        if p in st.session_state.cache_pdf_pages:
                            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿
                            st.image(
                                st.session_state.cache_pdf_pages[p],
                                caption=f"Page {p} (cached)",
                                use_column_width=True,
                            )
                        else:
                            # PDFã‹ã‚‰èª­ã¿è¾¼ã¿
                            with st.spinner(f"ğŸ“„ Page {p} èª­ã¿è¾¼ã¿ä¸­..."):
                                page_image = load_pdf_page(PDF_PATH, p)
                                st.session_state.cache_pdf_pages[p] = page_image
                                st.image(
                                    page_image,
                                    caption=f"Page {p}",
                                    use_column_width=True,
                                )


if __name__ == "__main__":
    render_education_gpt_page()
